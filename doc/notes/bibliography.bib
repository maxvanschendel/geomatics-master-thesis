
@inproceedings{badino_real-time_2012,
	title = {Real-time topometric localization},
	doi = {10.1109/ICRA.2012.6224716},
	abstract = {Autonomous vehicles must be capable of localizing even in GPS denied situations. In this paper, we propose a real-time method to localize a vehicle along a route using visual imagery or range information. Our approach is an implementation of topometric localization, which combines the robustness of topological localization with the geometric accuracy of metric methods. We construct a map by navigating the route using a GPS-equipped vehicle and building a compact database of simple visual and 3D features. We then localize using a Bayesian filter to match sequences of visual or range measurements to the database. The algorithm is reliable across wide environmental changes, including lighting differences, seasonal variations, and occlusions, achieving an average localization accuracy of 1 m over an 8 km route. The method converges correctly even with wrong initial position estimates solving the kidnapped robot problem.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Badino, Hernán and Huber, Daniel and Kanade, Takeo},
	month = may,
	year = {2012},
	note = {ISSN: 1050-4729},
	keywords = {Databases, Feature extraction, Global Positioning System, Measurement, Probability density function, Vehicles, Visualization},
	pages = {1635--1642},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\max.van.schendel\\Zotero\\storage\\RE5BZNP8\\6224716.html:text/html;Submitted Version:C\:\\Users\\max.van.schendel\\Zotero\\storage\\WNQHT6WC\\Badino et al. - 2012 - Real-time topometric localization.pdf:application/pdf},
}

@inproceedings{badino_real-time_2012-1,
	title = {Real-time topometric localization},
	doi = {10.1109/ICRA.2012.6224716},
	abstract = {Autonomous vehicles must be capable of localizing even in GPS denied situations. In this paper, we propose a real-time method to localize a vehicle along a route using visual imagery or range information. Our approach is an implementation of topometric localization, which combines the robustness of topological localization with the geometric accuracy of metric methods. We construct a map by navigating the route using a GPS-equipped vehicle and building a compact database of simple visual and 3D features. We then localize using a Bayesian filter to match sequences of visual or range measurements to the database. The algorithm is reliable across wide environmental changes, including lighting differences, seasonal variations, and occlusions, achieving an average localization accuracy of 1 m over an 8 km route. The method converges correctly even with wrong initial position estimates solving the kidnapped robot problem.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Badino, Hernán and Huber, Daniel and Kanade, Takeo},
	month = may,
	year = {2012},
	note = {ISSN: 1050-4729},
	keywords = {Databases, Feature extraction, Global Positioning System, Measurement, Probability density function, Vehicles, Visualization},
	pages = {1635--1642},
	file = {Submitted Version:C\:\\Users\\max.van.schendel\\Zotero\\storage\\89F8FRU6\\Badino et al. - 2012 - Real-time topometric localization.pdf:application/pdf},
}

@inproceedings{badino_real-time_2012-2,
	title = {Real-time topometric localization},
	doi = {10.1109/ICRA.2012.6224716},
	abstract = {Autonomous vehicles must be capable of localizing even in GPS denied situations. In this paper, we propose a real-time method to localize a vehicle along a route using visual imagery or range information. Our approach is an implementation of topometric localization, which combines the robustness of topological localization with the geometric accuracy of metric methods. We construct a map by navigating the route using a GPS-equipped vehicle and building a compact database of simple visual and 3D features. We then localize using a Bayesian filter to match sequences of visual or range measurements to the database. The algorithm is reliable across wide environmental changes, including lighting differences, seasonal variations, and occlusions, achieving an average localization accuracy of 1 m over an 8 km route. The method converges correctly even with wrong initial position estimates solving the kidnapped robot problem.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Badino, Hernán and Huber, Daniel and Kanade, Takeo},
	month = may,
	year = {2012},
	note = {ISSN: 1050-4729},
	keywords = {Databases, Feature extraction, Global Positioning System, Measurement, Probability density function, Vehicles, Visualization},
	pages = {1635--1642},
	file = {Submitted Version:C\:\\Users\\max.van.schendel\\Zotero\\storage\\C83XH25C\\Badino et al. - 2012 - Real-time topometric localization.pdf:application/pdf},
}

@inproceedings{oliveira_topometric_2020,
	address = {Cham},
	series = {Springer {Proceedings} in {Advanced} {Robotics}},
	title = {Topometric {Localization} with {Deep} {Learning}},
	isbn = {978-3-030-28619-4},
	doi = {10.1007/978-3-030-28619-4_38},
	abstract = {Compared to LiDAR-based localization methods, which provide high accuracy but rely on expensive sensors, visual localization approaches only require a camera and thus are more cost-effective however their accuracy and reliability is typically inferior to LiDAR-based methods. In this work, we propose a vision-based localization approach that learns from LiDAR-based localization methods by using their output as training data, thus combining a cheap, passive sensor with an accuracy that is on-par with LiDAR-based localization. The approach consists of two deep networks trained on visual odometry and topological localization, respectively, and a successive optimization to combine the predictions of these two networks. Furthermore, we introduce a new challenging pedestrian-based dataset for localization with a high degree of noise. Results obtained by evaluating the proposed approach on this novel dataset demonstrate localization errors up to 10 times smaller than those obtained with traditional vision-based localization methods.},
	language = {en},
	booktitle = {Robotics {Research}},
	publisher = {Springer International Publishing},
	author = {Oliveira, Gabriel L. and Radwan, Noha and Burgard, Wolfram and Brox, Thomas},
	editor = {Amato, Nancy M. and Hager, Greg and Thomas, Shawna and Torres-Torriti, Miguel},
	year = {2020},
	pages = {505--520},
}

@inproceedings{henein_exploring_2017,
	address = {Vancouver, BC},
	title = {Exploring the effect of meta-structural information on the global consistency of {SLAM}},
	isbn = {978-1-5386-2682-5},
	url = {http://ieeexplore.ieee.org/document/8205970/},
	doi = {10.1109/IROS.2017.8205970},
	abstract = {Accurate online estimation of the environment structure simultaneously with the robot pose is a key capability for autonomous robotic vehicles. Classical simultaneous localization and mapping (SLAM) algorithms make no assumptions about the conﬁguration of the points in the environment, however, real world scenes have signiﬁcant structure (ground planes, buildings, walls, ceilings, etc..) that can be exploited. In this paper, we introduce meta-structural information associated with geometric primitives into the estimation problem and analyze their effect on the global structural consistency of the resulting map. Although we only consider the effect of adding planar and orthogonality information for the estimation of 3D points in a Manhattan-like world, this framework can be extended to any type of geometric, kinematic, dynamic or even semantic information. We evaluate our approach on a city-like simulated environment. We highlight the advantages of the proposed solution over SLAM formulation considering no prior knowledge about the conﬁguration of 3D points in the environment.},
	language = {en},
	urldate = {2021-10-11},
	booktitle = {2017 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	publisher = {IEEE},
	author = {Henein, Mina and Abello, Montiel and Ila, Viorela and Mahony, Robert},
	month = sep,
	year = {2017},
	pages = {1616--1623},
	file = {Henein et al. - 2017 - Exploring the effect of meta-structural informatio.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\EXP4QX34\\Henein et al. - 2017 - Exploring the effect of meta-structural informatio.pdf:application/pdf},
}

@book{akella_algorithmic_2008,
	address = {Berlin, Heidelberg},
	series = {Springer {Tracts} in {Advanced} {Robotics}},
	title = {Algorithmic {Foundation} of {Robotics} {VII}: {Selected} {Contributions} of the {Seventh} {International} {Workshop} on the {Algorithmic} {Foundations} of {Robotics}},
	volume = {47},
	isbn = {978-3-540-68404-6 978-3-540-68405-3},
	shorttitle = {Algorithmic {Foundation} of {Robotics} {VII}},
	url = {http://link.springer.com/10.1007/978-3-540-68405-3},
	language = {en},
	urldate = {2021-10-11},
	publisher = {Springer Berlin Heidelberg},
	editor = {Akella, Srinivas and Amato, Nancy M. and Huang, Wesley H. and Mishra, Bud and Siciliano, Bruno and Khatib, Oussama and Groen, Frans},
	year = {2008},
	doi = {10.1007/978-3-540-68405-3},
	file = {Akella et al. - 2008 - Algorithmic Foundation of Robotics VII Selected C.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\8R3ZYM9Y\\Akella et al. - 2008 - Algorithmic Foundation of Robotics VII Selected C.pdf:application/pdf},
}

@book{alami_distributed_2007,
	address = {Tokyo ; New York},
	title = {Distributed autonomous robotic system 6},
	isbn = {978-4-431-35869-5},
	language = {en},
	publisher = {Springer},
	editor = {Alami, Rachid and Chatila, Raja and Asama, H.},
	year = {2007},
	note = {Meeting Name: International Symposium on Distributed Autonomous Robotic Systems
OCLC: ocn144524594},
	keywords = {Autonomous robots, Congresses},
	file = {Alami et al. - 2007 - Distributed autonomous robotic system 6.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\ZSTW6JZ7\\Alami et al. - 2007 - Distributed autonomous robotic system 6.pdf:application/pdf},
}

@article{fischer_stickypillars_2021,
	title = {{StickyPillars}: {Robust} and {Efficient} {Feature} {Matching} on {Point} {Clouds} using {Graph} {Neural} {Networks}},
	shorttitle = {{StickyPillars}},
	url = {http://arxiv.org/abs/2002.03983},
	abstract = {Robust point cloud registration in real-time is an important prerequisite for many mapping and localization algorithms. Traditional methods like ICP tend to fail without good initialization, insufﬁcient overlap or in the presence of dynamic objects. Modern deep learning based registration approaches present much better results, but suffer from a heavy run-time. We overcome these drawbacks by introducing StickyPillars, a fast, accurate and extremely robust deep middle-end 3D feature matching method on point clouds. It uses graph neural networks and performs context aggregation on sparse 3D key-points with the aid of transformer based multi-head self and cross-attention. The network output is used as the cost for an optimal transport problem whose solution yields the ﬁnal matching probabilities. The system does not rely on hand crafted feature descriptors or heuristic matching strategies. We present state-of-art art accuracy results on the registration problem demonstrated on the KITTI dataset while being four times faster then leading deep methods. Furthermore, we integrate our matching system into a LiDAR odometry pipeline yielding most accurate results on the KITTI odometry dataset. Finally, we demonstrate robustness on KITTI odometry. Our method remains stable in accuracy where state-of-the-art procedures fail on frame drops and higher speeds.},
	language = {en},
	urldate = {2021-09-29},
	journal = {arXiv:2002.03983 [cs]},
	author = {Fischer, Kai and Simon, Martin and Oelsner, Florian and Milz, Stefan and Gross, Horst-Michael and Maeder, Patrick},
	month = feb,
	year = {2021},
	note = {arXiv: 2002.03983},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Fischer et al. - 2021 - StickyPillars Robust and Efficient Feature Matchi.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\Q3LPRY9J\\Fischer et al. - 2021 - StickyPillars Robust and Efficient Feature Matchi.pdf:application/pdf},
}

@inproceedings{been_kim_multiple_2010,
	address = {Anchorage, AK},
	title = {Multiple relative pose graphs for robust cooperative mapping},
	isbn = {978-1-4244-5038-1},
	url = {http://ieeexplore.ieee.org/document/5509154/},
	doi = {10.1109/ROBOT.2010.5509154},
	abstract = {This paper describes a new algorithm for cooperative and persistent simultaneous localization and mapping (SLAM) using multiple robots. Recent pose graph representations have proven very successful for single robot mapping and localization. Among these methods, incremental smoothing and mapping (iSAM) gives an exact incremental solution to the SLAM problem by solving a full nonlinear optimization problem in real-time. In this paper, we present a novel extension to iSAM to facilitate online multi-robot mapping based on multiple pose graphs. Our main contribution is a relative formulation of the relationship between multiple pose graphs that avoids the initialization problem and leads to an efﬁcient solution when compared to a completely global formulation. The relative pose graphs are optimized together to provide a globally consistent multi-robot solution. Efﬁcient access to covariances at any time for relative parameters is provided through iSAM, facilitating data association and loop closing. The performance of the technique is illustrated on various data sets including a publicly available multi-robot data set. Further evaluation is performed in a collaborative helicopter and ground robot experiment.},
	language = {en},
	urldate = {2021-09-28},
	booktitle = {2010 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	publisher = {IEEE},
	author = {{Been Kim} and Kaess, Michael and Fletcher, Luke and Leonard, John and Bachrach, Abraham and Roy, Nicholas and Teller, Seth},
	month = may,
	year = {2010},
	pages = {3185--3192},
	file = {Been Kim et al. - 2010 - Multiple relative pose graphs for robust cooperati.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\DH3SHXQC\\Been Kim et al. - 2010 - Multiple relative pose graphs for robust cooperati.pdf:application/pdf},
}

@article{saeedi_multiple-robot_2016,
	title = {Multiple-{Robot} {Simultaneous} {Localization} and {Mapping}: {A} {Review}: {Multiple}-{Robot} {Simultaneous} {Localization} and {Mapping}},
	volume = {33},
	issn = {15564959},
	shorttitle = {Multiple-{Robot} {Simultaneous} {Localization} and {Mapping}},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/rob.21620},
	doi = {10.1002/rob.21620},
	abstract = {Simultaneous localization and mapping (SLAM) in unknown GPS-denied environments is a major challenge for researchers in the ﬁeld of mobile robotics. There exist many solutions for single-robot SLAM; however, moving to a platform of multiple robots adds many challenges to the existing problems. This paper reviews state-of-the-art multiple-robot systems, with a major focus on multiplerobot SLAM. Various issues and problems in multiple-robot SLAM are introduced, current solutions for these problems are reviewed, and their advantages and disadvantages are discussed.},
	language = {en},
	number = {1},
	urldate = {2021-09-28},
	journal = {Journal of Field Robotics},
	author = {Saeedi, Sajad and Trentini, Michael and Seto, Mae and Li, Howard},
	month = jan,
	year = {2016},
	pages = {3--46},
	file = {Saeedi et al. - 2016 - Multiple-Robot Simultaneous Localization and Mappi.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\G4TEQ3M3\\Saeedi et al. - 2016 - Multiple-Robot Simultaneous Localization and Mappi.pdf:application/pdf},
}

@inproceedings{labbe_online_2014,
	address = {Chicago, IL, USA},
	title = {Online global loop closure detection for large-scale multi-session graph-based {SLAM}},
	isbn = {978-1-4799-6934-0 978-1-4799-6931-9},
	url = {http://ieeexplore.ieee.org/document/6942926/},
	doi = {10.1109/IROS.2014.6942926},
	abstract = {For large-scale and long-term simultaneous localization and mapping (SLAM), a robot has to deal with unknown initial positioning caused by either the kidnapped robot problem or multi-session mapping. This paper addresses these problems by tying the SLAM system with a global loop closure detection approach, which intrinsically handles these situations. However, online processing for global loop closure detection approaches is generally inﬂuenced by the size of the environment. The proposed graph-based SLAM system uses a memory management approach that only consider portions of the map to satisfy online processing requirements. The approach is tested and demonstrated using ﬁve indoor mapping sessions of a building using a robot equipped with a laser rangeﬁnder and a Kinect.},
	language = {en},
	urldate = {2021-09-28},
	booktitle = {2014 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	publisher = {IEEE},
	author = {Labbe, Mathieu and Michaud, Francois},
	month = sep,
	year = {2014},
	pages = {2661--2666},
	file = {Labbe and Michaud - 2014 - Online global loop closure detection for large-sca.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\GE9RHMRS\\Labbe and Michaud - 2014 - Online global loop closure detection for large-sca.pdf:application/pdf},
}

@article{lu_globally_1997,
	title = {Globally {Consistent} {Range} {Scan} {Alignment} for {Environment} {Mapping}},
	abstract = {A robot exploring an unknown environment may need to build a world model from sensor measurements. In order to integrate all the frames of sensor data, it is essential to align the data properly. An incremental approach has been typically used in the past, in which each local frame of data is aligned to a cumulative global model, and then merged to the model. Because different parts of the model are updated independently while there are errors in the registration, such an approach may result in an inconsistent model.},
	language = {en},
	author = {Lu, F and Milios, E},
	year = {1997},
	pages = {17},
	file = {Lu and Milios - 1997 - Globally Consistent Range Scan Alignment for Envir.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\UPDPCWZY\\Lu and Milios - 1997 - Globally Consistent Range Scan Alignment for Envir.pdf:application/pdf},
}

@inproceedings{bailey_consistency_2006,
	address = {Beijing},
	title = {Consistency of the {EKF}-{SLAM} {Algorithm}},
	isbn = {978-1-4244-0258-8},
	url = {http://ieeexplore.ieee.org/document/4058955/},
	doi = {10.1109/IROS.2006.281644},
	abstract = {This paper presents an analysis of the extended Kalman ﬁlter formulation of simultaneous localisation and mapping (EKF-SLAM). We show that the algorithm produces very optimistic estimates once the “true” uncertainty in vehicle heading exceeds a limit. This failure is subtle and cannot, in general, be detected without ground-truth, although a very inconsistent ﬁlter may exhibit observable symptoms, such as disproportionately large jumps in the vehicle pose update. Conventional solutions—adding stabilising noise, using an iterated EKF or unscented ﬁlter, etc—do not improve the situation. However, if “small” heading uncertainty is maintained, EKF-SLAM exhibits consistent behaviour over an extended time-period. Although the uncertainty estimate slowly becomes optimistic, inconsistency can be mitigated indeﬁnitely by applying tactics such as batch updates or stabilising noise. The manageable degradation of small heading variance SLAM indicates the efﬁcacy of submap methods for large-scale maps.},
	language = {en},
	urldate = {2021-09-28},
	booktitle = {2006 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	publisher = {IEEE},
	author = {Bailey, Tim and Nieto, Juan and Guivant, Jose and Stevens, Michael and Nebot, Eduardo},
	month = oct,
	year = {2006},
	pages = {3562--3568},
	file = {Bailey et al. - 2006 - Consistency of the EKF-SLAM Algorithm.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\PGX4P95G\\Bailey et al. - 2006 - Consistency of the EKF-SLAM Algorithm.pdf:application/pdf},
}

@article{smith_representation_1986,
	title = {On the {Representation} and {Estimation} of {Spatial} {Uncertainty}},
	volume = {5},
	issn = {0278-3649, 1741-3176},
	url = {http://journals.sagepub.com/doi/10.1177/027836498600500404},
	doi = {10.1177/027836498600500404},
	abstract = {This paper describes a general method for estimating the nominal relationshipand expected error (covariance)between coordinateframes representing the relative locations of objects. Theframes may be known only indirectly through a series of spatial relationships, each with its associated error, arisingfrom diverse causes, includingpositioning errors, measurement errors, or tolerances in part dimensions. This estimation method can be used to answer such questions as whether a camera attached,to a robot is likely to have a particular referenceobject in itsfield of view. The calculated estimates agree well with those/rom an independent Monte Carlo simulation. The method makes it possible to decide in advance whether an uncertain relationship is known accurately enoughfor some task and, i f not, how much of an improvement in locational knowledge a proposed sensor will provide. The method presented can be generalized to six degrees offreedom and provides a practical means of estimating the relationships(position and orientation)among objects, as well as estimating the uncertainty associated with the relationships.},
	language = {en},
	number = {4},
	urldate = {2021-09-28},
	journal = {The International Journal of Robotics Research},
	author = {Smith, Randall C. and Cheeseman, Peter},
	month = dec,
	year = {1986},
	pages = {56--68},
	file = {Smith and Cheeseman - 1986 - On the Representation and Estimation of Spatial Un.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\6HJENB86\\Smith and Cheeseman - 1986 - On the Representation and Estimation of Spatial Un.pdf:application/pdf},
}

@article{smith_estimating_nodate,
	title = {Estimating {Uncertain} {Spatial} {Relationships} in {Robotics}},
	language = {en},
	author = {Smith, Randall and Self, Matthew and Cheeseman, Peter},
	pages = {26},
	file = {Smith et al. - Estimating Uncertain Spatial Relationships in Robo.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\5JLBFCSN\\Smith et al. - Estimating Uncertain Spatial Relationships in Robo.pdf:application/pdf},
}

@article{montemerlo_fastslam_nodate,
	title = {{FastSLAM}: {A} {Factored} {Solution} to the {Simultaneous} {Localization} and {Mapping} {Problem}},
	abstract = {The ability to simultaneously localize a robot and accurately map its surroundings is considered by many to be a key prerequisite of truly autonomous robots. However, few approaches to this problem scale up to handle the very large number of landmarks present in real environments. Kalman ﬁlter-based algorithms, for example, require time quadratic in the number of landmarks to incorporate each sensor observation. This paper presents FastSLAM, an algorithm that recursively estimates the full posterior distribution over robot pose and landmark locations, yet scales logarithmically with the number of landmarks in the map. This algorithm is based on an exact factorization of the posterior into a product of conditional landmark distributions and a distribution over robot paths. The algorithm has been run successfully on as many as 50,000 landmarks, environments far beyond the reach of previous approaches. Experimental results demonstrate the advantages and limitations of the FastSLAM algorithm on both simulated and realworld data.},
	language = {en},
	author = {Montemerlo, Michael and Thrun, Sebastian and Koller, Daphne and Wegbreit, Ben},
	pages = {6},
	file = {Montemerlo et al. - FastSLAM A Factored Solution to the Simultaneous .pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\INPQ8EY2\\Montemerlo et al. - FastSLAM A Factored Solution to the Simultaneous .pdf:application/pdf},
}

@article{mur-artal_orb-slam2_2017,
	title = {{ORB}-{SLAM2}: an {Open}-{Source} {SLAM} {System} for {Monocular}, {Stereo} and {RGB}-{D} {Cameras}},
	volume = {33},
	issn = {1552-3098, 1941-0468},
	shorttitle = {{ORB}-{SLAM2}},
	url = {http://arxiv.org/abs/1610.06475},
	doi = {10.1109/TRO.2017.2705103},
	abstract = {We present ORB-SLAM2 a complete SLAM system for monocular, stereo and RGB-D cameras, including map reuse, loop closing and relocalization capabilities. The system works in real-time on standard CPUs in a wide variety of environments from small hand-held indoors sequences, to drones ﬂying in industrial environments and cars driving around a city. Our back-end based on bundle adjustment with monocular and stereo observations allows for accurate trajectory estimation with metric scale. Our system includes a lightweight localization mode that leverages visual odometry tracks for unmapped regions and matches to map points that allow for zero-drift localization. The evaluation on 29 popular public sequences shows that our method achieves state-of-the-art accuracy, being in most cases the most accurate SLAM solution. We publish the source code, not only for the beneﬁt of the SLAM community, but with the aim of being an out-of-the-box SLAM solution for researchers in other ﬁelds.},
	language = {en},
	number = {5},
	urldate = {2021-09-24},
	journal = {IEEE Transactions on Robotics},
	author = {Mur-Artal, Raul and Tardos, Juan D.},
	month = oct,
	year = {2017},
	note = {arXiv: 1610.06475},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	pages = {1255--1262},
	annote = {Comment: Accepted for publication in IEEE Transactions on Robotics},
	file = {Mur-Artal and Tardos - 2017 - ORB-SLAM2 an Open-Source SLAM System for Monocula.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\CYR7BWQY\\Mur-Artal and Tardos - 2017 - ORB-SLAM2 an Open-Source SLAM System for Monocula.pdf:application/pdf},
}

@article{yousif_overview_2015,
	title = {An {Overview} to {Visual} {Odometry} and {Visual} {SLAM}: {Applications} to {Mobile} {Robotics}},
	volume = {1},
	issn = {2363-6912, 2199-854X},
	shorttitle = {An {Overview} to {Visual} {Odometry} and {Visual} {SLAM}},
	url = {http://link.springer.com/10.1007/s40903-015-0032-7},
	doi = {10.1007/s40903-015-0032-7},
	abstract = {This paper is intended to pave the way for new researchers in the ﬁeld of robotics and autonomous systems, particularly those who are interested in robot localization and mapping. We discuss the fundamentals of robot navigation requirements and provide a review of the state of the art techniques that form the bases of established solutions for mobile robots localization and mapping. The topics we discuss range from basic localization techniques such as wheel odometry and dead reckoning, to the more advance Visual Odometry (VO) and Simultaneous Localization and Mapping (SLAM) techniques. We discuss VO in both monocular and stereo vision systems using feature matching/tracking and optical ﬂow techniques. We discuss and compare the basics of most common SLAM methods such as the Extended Kalman Filter SLAM (EKF-SLAM), Particle Filter and the most recent RGB-D SLAM. We also provide techniques that form the building blocks to those methods such as feature extraction (i.e. SIFT, SURF, FAST), feature matching, outlier removal and data association techniques.},
	language = {en},
	number = {4},
	urldate = {2021-09-24},
	journal = {Intelligent Industrial Systems},
	author = {Yousif, Khalid and Bab-Hadiashar, Alireza and Hoseinnezhad, Reza},
	month = dec,
	year = {2015},
	pages = {289--311},
	file = {Yousif et al. - 2015 - An Overview to Visual Odometry and Visual SLAM Ap.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\S9G9864V\\Yousif et al. - 2015 - An Overview to Visual Odometry and Visual SLAM Ap.pdf:application/pdf},
}

@article{kegeleirs_swarm_2021,
	title = {Swarm {SLAM}: {Challenges} and {Perspectives}},
	volume = {8},
	issn = {2296-9144},
	shorttitle = {Swarm {SLAM}},
	url = {https://www.frontiersin.org/articles/10.3389/frobt.2021.618268/full},
	doi = {10.3389/frobt.2021.618268},
	abstract = {A robot swarm is a decentralized system characterized by locality of sensing and communication, self-organization, and redundancy. These characteristics allow robot swarms to achieve scalability, ﬂexibility and fault tolerance, properties that are especially valuable in the context of simultaneous localization and mapping (SLAM), speciﬁcally in unknown environments that evolve over time. So far, research in SLAM has mainly focused on single- and centralized multi-robot systems—i.e., non-swarm systems. While these systems can produce accurate maps, they are typically not scalable, cannot easily adapt to unexpected changes in the environment, and are prone to failure in hostile environments. Swarm SLAM is a promising approach to SLAM as it could leverage the decentralized nature of a robot swarm and achieve scalable, ﬂexible and fault-tolerant exploration and mapping. However, at the moment of writing, swarm SLAM is a rather novel idea and the ﬁeld lacks deﬁnitions, frameworks, and results. In this work, we present the concept of swarm SLAM and its constraints, both from a technical and an economical point of view. In particular, we highlight the main challenges of swarm SLAM for gathering, sharing, and retrieving information. We also discuss the strengths and weaknesses of this approach against traditional multi-robot SLAM. We believe that swarm SLAM will be particularly useful to produce abstract maps such as topological or simple semantic maps and to operate under time or cost constraints.},
	language = {en},
	urldate = {2021-09-24},
	journal = {Frontiers in Robotics and AI},
	author = {Kegeleirs, Miquel and Grisetti, Giorgio and Birattari, Mauro},
	month = mar,
	year = {2021},
	pages = {618268},
	file = {Kegeleirs et al. - 2021 - Swarm SLAM Challenges and Perspectives.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\LR7WV4IV\\Kegeleirs et al. - 2021 - Swarm SLAM Challenges and Perspectives.pdf:application/pdf},
}

@book{thrun_probabilistic_2005,
	address = {Cambridge, Mass},
	series = {Intelligent robotics and autonomous agents},
	title = {Probabilistic robotics},
	isbn = {978-0-262-20162-9},
	publisher = {MIT Press},
	author = {Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
	year = {2005},
	note = {OCLC: ocm58451645},
	keywords = {Probabilities, Robotics},
	file = {Thrun - 2002 - Probabilistic robotics.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\46W4XZ3K\\Thrun - 2002 - Probabilistic robotics.pdf:application/pdf},
}

@book{strang_introduction_2016,
	address = {Wellesley},
	edition = {5th edition},
	title = {Introduction to linear algebra},
	isbn = {978-0-9802327-7-6},
	language = {eng},
	publisher = {Cambridge press},
	author = {Strang, Gilbert},
	year = {2016},
	file = {Introduction to Linear Algebra (3rd Edition) 2003 Gilbert Strang.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\DB6E8P6L\\Introduction to Linear Algebra (3rd Edition) 2003 Gilbert Strang.pdf:application/pdf},
}

@book{lang_introduction_1986,
	address = {New York},
	title = {Introduction to linear algebra},
	isbn = {978-0-387-96205-4 978-3-540-96205-2},
	language = {English},
	publisher = {Springer-Verlag},
	author = {Lang, Serge},
	year = {1986},
	note = {OCLC: 12236024},
}

@inproceedings{ragot_benchmark_2019,
	address = {Colchester, United Kingdom},
	title = {Benchmark of {Visual} {SLAM} {Algorithms}: {ORB}-{SLAM2} vs {RTAB}-{Map}*},
	isbn = {978-1-72815-546-3},
	shorttitle = {Benchmark of {Visual} {SLAM} {Algorithms}},
	url = {https://ieeexplore.ieee.org/document/8806213/},
	doi = {10.1109/EST.2019.8806213},
	abstract = {This works deals with a benchmark of two wellknown visual Simultaneous Localization and Mapping (vSLAM) algorithms: ORB-SLAM2 proposed by Mur-Atal \& al in 2015 [7] and RTAB-Map proposed by [8]. The benchmark has been carried out with an Intel real-sense camera 435D mounted on top of a robotics electrical powered wheelchair running a ROS platform. The ORB SLAM has been implemented taking into account a monocular, stereo and RGB-D camera. RTAB SLAM, meanwhile, has only implemented with monocular and RGBD camera. Several experiments have been carried out in a controlled indoor environment at the ESIGELEC’s Autonomous Navigation Laboratory. These experiments are supported by the use of the VICON motion capture system used as a groundtruth to validate our results [1]. Different motion scenarios are used to test and benchmark the SLAM algorithms in various conﬁgurations: straight-line, straight-line and back, circular path with loop closure, etc.},
	language = {en},
	urldate = {2021-09-17},
	booktitle = {2019 {Eighth} {International} {Conference} on {Emerging} {Security} {Technologies} ({EST})},
	publisher = {IEEE},
	author = {Ragot, Nicolas and Khemmar, Redouane and Pokala, Adithya and Rossi, Romain and Ertaud, Jean-Yves},
	month = jul,
	year = {2019},
	pages = {1--6},
	file = {Ragot et al. - 2019 - Benchmark of Visual SLAM Algorithms ORB-SLAM2 vs .pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\AMRQPH8B\\Ragot et al. - 2019 - Benchmark of Visual SLAM Algorithms ORB-SLAM2 vs .pdf:application/pdf},
}

@article{liu_rds-slam_2021,
	title = {{RDS}-{SLAM}: {Real}-{Time} {Dynamic} {SLAM} {Using} {Semantic} {Segmentation} {Methods}},
	volume = {9},
	issn = {2169-3536},
	shorttitle = {{RDS}-{SLAM}},
	url = {https://ieeexplore.ieee.org/document/9318990/},
	doi = {10.1109/ACCESS.2021.3050617},
	abstract = {The scene rigidity is a strong assumption in typical visual Simultaneous Localization and Mapping (vSLAM) algorithms. Such strong assumption limits the usage of most vSLAM in dynamic real-world environments, which are the target of several relevant applications such as augmented reality, semantic mapping, unmanned autonomous vehicles, and service robotics. Many solutions are proposed that use different kinds of semantic segmentation methods (e.g., Mask R-CNN, SegNet) to detect dynamic objects and remove outliers. However, as far as we know, such kind of methods wait for the semantic results in the tracking thread in their architecture, and the processing time depends on the segmentation methods used. In this paper, we present RDS-SLAM, a real-time visual dynamic SLAM algorithm that is built on ORB-SLAM3 and adds a semantic thread and a semantic-based optimization thread for robust tracking and mapping in dynamic environments in real-time. These novel threads run in parallel with the others, and therefore the tracking thread does not need to wait for the semantic information anymore. Besides, we propose an algorithm to obtain as the latest semantic information as possible, thereby making it possible to use segmentation methods with different speeds in a uniform way. We update and propagate semantic information using the moving probability, which is saved in the map and used to remove outliers from tracking using a data association algorithm. Finally, we evaluate the tracking accuracy and real-time performance using the public TUM RGB-D datasets and Kinect camera in dynamic indoor scenarios.},
	language = {en},
	urldate = {2021-09-17},
	journal = {IEEE Access},
	author = {Liu, Yubao and Miura, Jun},
	year = {2021},
	pages = {23772--23785},
	file = {Liu and Miura - 2021 - RDS-SLAM Real-Time Dynamic SLAM Using Semantic Se.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\LAK97UZK\\Liu and Miura - 2021 - RDS-SLAM Real-Time Dynamic SLAM Using Semantic Se.pdf:application/pdf},
}

@inproceedings{alves_remote_2020,
	address = {Ponta Delgada, Portugal},
	title = {A {Remote} {RGB}-{D} {VSLAM} {Solution} for {Low} {Computational} {Powered} {Robots}},
	isbn = {978-1-72817-078-7},
	url = {https://ieeexplore.ieee.org/document/9096074/},
	doi = {10.1109/ICARSC49921.2020.9096074},
	language = {en},
	urldate = {2021-09-17},
	booktitle = {2020 {IEEE} {International} {Conference} on {Autonomous} {Robot} {Systems} and {Competitions} ({ICARSC})},
	publisher = {IEEE},
	author = {Alves, Joao and Bernardino, Alexandre},
	month = apr,
	year = {2020},
	pages = {214--220},
	annote = {Describes 16-bit image compression method for wireless transfer of RGBD images},
	file = {Alves and Bernardino - 2020 - A Remote RGB-D VSLAM Solution for Low Computationa.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\PQ3MLD3V\\Alves and Bernardino - 2020 - A Remote RGB-D VSLAM Solution for Low Computationa.pdf:application/pdf},
}

@inproceedings{yue_multi-robot_2019,
	address = {Bangkok, Thailand},
	title = {Multi-{Robot} {Map} {Fusion} {Framework} using {Heterogeneous} {Sensors}},
	isbn = {978-1-72813-458-1},
	url = {https://ieeexplore.ieee.org/document/9095798/},
	doi = {10.1109/CIS-RAM47153.2019.9095798},
	abstract = {Fusing local 3D maps generated by individual robots to a globally consistent 3D map is a fundamental challenge in multi-robot missions. With the emergence of diverse sensors, different robots could carry heterogeneous sensors(laser scanners and vision-based sensor). However, there have been few works on real time 3D map fusion with different map data type, especially merging the sparse map with the dense map. In this paper, a general probabilistic framework is proposed to address the integrated map fusion problem, which is independent of sensor types and SLAM algorithms. The multiple data association method between those different types of map provides good insights into merging maps with the different physical and geometrical properties. This paper also provides a timesequential map merging framework that makes fusing maps from distributed multi-robot system efﬁciently. The proposed approach is evaluated using mapping data collected from both indoor and mixed indoor-outdoor environments with heterogeneous sensors, which shows its robustness and generality in 3D map fusion for multi-robot mapping missions.},
	language = {en},
	urldate = {2021-07-23},
	booktitle = {2019 {IEEE} {International} {Conference} on {Cybernetics} and {Intelligent} {Systems} ({CIS}) and {IEEE} {Conference} on {Robotics}, {Automation} and {Mechatronics} ({RAM})},
	publisher = {IEEE},
	author = {Yue, Yufeng and Yang, Chule and Wang, Yuanzhe and Zhang, Jun and Wen, Mingxing and Tang, Xiaoyu and Zhang, Haoyuan and Wang, Danwei},
	month = nov,
	year = {2019},
	pages = {536--541},
	file = {Yue et al. - 2019 - Multi-Robot Map Fusion Framework using Heterogeneo.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\HXCAYXEE\\Yue et al. - 2019 - Multi-Robot Map Fusion Framework using Heterogeneo.pdf:application/pdf},
}

@article{yue_multilevel_2020,
	title = {A {Multilevel} {Fusion} {System} for {Multirobot} 3-{D} {Mapping} {Using} {Heterogeneous} {Sensors}},
	volume = {14},
	issn = {1932-8184, 1937-9234, 2373-7816},
	url = {https://ieeexplore.ieee.org/document/8768358/},
	doi = {10.1109/JSYST.2019.2927042},
	abstract = {Operating multiple robots in an unstructured environment is challenging due to its high complexity and uncertainty. In such applications, the integration of individual maps generated by heterogeneous sensors is a critical problem, especially the fusion of sparse and dense maps. This paper proposes a general multilevel probabilistic framework to address the integrated map fusion problem, which is independent of sensor type and SLAM algorithm employed. The key novelty of this paper is the mathematical formulation of the overall map fusion problem and the derivation of its probabilistic decomposition. The framework provides a theoretical basis for computing the relative transformations amongst robots and merging probabilistic map information. Since the maps generated by heterogeneous sensors have different physical properties, an expectation-maximization-based map-matching algorithm is proposed which automatically determines the number of voxels to be associated. Then, a time-sequential map merging strategy is developed to generate a globally consistent map. The proposed approach is evaluated in various environments with heterogeneous sensors, which demonstrates its accuracy and versatility in 3-D multirobot map fusion missions.},
	language = {en},
	number = {1},
	urldate = {2021-07-23},
	journal = {IEEE Systems Journal},
	author = {Yue, Yufeng and Yang, Chule and Wang, Yuanzhe and Senarathne, P. G. Chaminda Namal and Zhang, Jun and Wen, Mingxing and Wang, Danwei},
	month = mar,
	year = {2020},
	pages = {1341--1352},
	annote = {Important
 },
	file = {Yue et al. - 2020 - A Multilevel Fusion System for Multirobot 3-D Mapp.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\PP3D9NQM\\Yue et al. - 2020 - A Multilevel Fusion System for Multirobot 3-D Mapp.pdf:application/pdf},
}

@article{jiang_simultaneously_2020,
	title = {Simultaneously merging multi-robot grid maps at different resolutions},
	volume = {79},
	issn = {1380-7501, 1573-7721},
	url = {http://link.springer.com/10.1007/s11042-018-7109-8},
	doi = {10.1007/s11042-018-7109-8},
	abstract = {For an unknown GPS-denied environment, multiple robots can explore various areas of the same environment and build local maps for these areas. Accordingly, it is essential to merge these local maps of different robots into one global map. For grid map merging, this paper proposes an effective approach, which can simultaneously merge multi-robot grid maps at different resolutions. First, we present a scaling pairwise method for merging grid map pairs. Usually, a selected grid map is initialized as the seed map, which is then sequentially updated by performing scaling pairwise merging between itself and other input grid maps. Afterwards, map augmentation and feature fusion strategy is proposed to alternatively integrate two local maps into one initial global map. To address the accumulated error, a coarse-to-fine method is introduced to refine the initial global map and obtain the accurate global map. Experimental results conducted on real robot data sets demonstrate that the proposed approach can merge multiple grid maps simultaneously at different resolutions with good performances.},
	language = {en},
	number = {21-22},
	urldate = {2021-07-23},
	journal = {Multimedia Tools and Applications},
	author = {Jiang, Zutao and Zhu, Jihua and Jin, Congcong and Xu, Siyu and Zhou, Yiqiong and Pang, Shanmin},
	month = jun,
	year = {2020},
	pages = {14553--14572},
	file = {Jiang et al. - 2020 - Simultaneously merging multi-robot grid maps at di.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\YX6UZGF2\\Jiang et al. - 2020 - Simultaneously merging multi-robot grid maps at di.pdf:application/pdf},
}

@article{endsley_toward_1995,
	title = {Toward a {Theory} of {Situation} {Awareness} in {Dynamic} {Systems}},
	volume = {37},
	issn = {0018-7208, 1547-8181},
	url = {http://journals.sagepub.com/doi/10.1518/001872095779049543},
	doi = {10.1518/001872095779049543},
	abstract = {This paper presents a theoretical model of situation awareness based on its role in dynamic human decision making in a variety of domains. Situation awareness is presented as a predominant concern in system operation, based on a descriptive view of decision making. The relationship between situation awareness and numerous individual and environmental factors is explored. Among these factors, attention and working memory are presented as critical factors limiting operators from acquiring and interpreting information from the environment to form situation awareness, and mental models and goal-directed behavior are hypothesized as important mechanisms for overcoming these limits. The impact of design features, workload, stress, system complexity, and automation on operator situation awareness is addressed, and a taxonomy of errors in situation awareness is introduced, based on the model presented. The model is used to generate design implications for enhancing operator situation awareness and future directions for situation awareness research.},
	language = {en},
	number = {1},
	urldate = {2021-07-19},
	journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
	author = {Endsley, Mica R.},
	month = mar,
	year = {1995},
	pages = {32--64},
	file = {Endsley - 1995 - Toward a Theory of Situation Awareness in Dynamic .pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\V9YIX45J\\Endsley - 1995 - Toward a Theory of Situation Awareness in Dynamic .pdf:application/pdf},
}

@article{chen_coordination_2008,
	title = {Coordination in emergency response management},
	volume = {51},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/1342327.1342340},
	doi = {10.1145/1342327.1342340},
	abstract = {Developing a framework to analyze coordination patterns occurring in the emergency response life cycle.},
	language = {en},
	number = {5},
	urldate = {2021-07-19},
	journal = {Communications of the ACM},
	author = {Chen, Rui and Sharman, Raj and Rao, H. Raghav and Upadhyaya, Shambhu J.},
	month = may,
	year = {2008},
	pages = {66--73},
	file = {Chen et al. - 2008 - Coordination in emergency response management.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\LKXBZRX4\\Chen et al. - 2008 - Coordination in emergency response management.pdf:application/pdf},
}

@article{turoff_design_nodate,
	title = {The {Design} of a {Dynamic} {Emergency} {Response} {Management} {Information} {System} ({DERMIS})},
	abstract = {This paper systematically develops a set of general and supporting design principles and specifications for a “Dynamic Emergency Response Management Information System” (DERMIS) by identifying design premises resulting from the use of the “Emergency Management Information System and Reference Index” (EMISARI) and design concepts resulting from a comprehensive literature review. Implicit in crises of varying scopes and proportions are communication and information needs that can be addressed by today’s information and communication technologies. However, what is required is organizing the premises and concepts that can be mapped into a set of generic design principles in turn providing a framework for the sensible development of flexible and dynamic Emergency Response Information Systems.},
	language = {en},
	author = {Turoff, Murray and Chumer, Michael},
	pages = {36},
	file = {Turoff and Chumer - The Design of a Dynamic Emergency Response Managem.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\6V2GMD3D\\Turoff and Chumer - The Design of a Dynamic Emergency Response Managem.pdf:application/pdf},
}

@article{kiss-illes_gps-slam_2019,
	title = {{GPS}-{SLAM}: {An} {Augmentation} of the {ORB}-{SLAM} {Algorithm}},
	volume = {19},
	issn = {1424-8220},
	shorttitle = {{GPS}-{SLAM}},
	url = {https://www.mdpi.com/1424-8220/19/22/4973},
	doi = {10.3390/s19224973},
	abstract = {This work presents Global Positioning System-Simultaneous Localization and Mapping (GPS-SLAM), an augmented version of Oriented FAST (Features from accelerated segment test) and Rotated BRIEF (Binary Robust Independent Elementary Features) feature detector (ORB)-SLAM using GPS and inertial data to make the algorithm capable of dealing with low frame rate datasets. In general, SLAM systems are successful in case of datasets with a high frame rate. This work was motivated by a scarce dataset where ORB-SLAM often loses track because of the lack of continuity. The main work includes the determination of the next frame’s pose based on the GPS and inertial data. The results show that this additional information makes the algorithm more robust. As many large, outdoor unmanned aerial vehicle (UAV) ﬂights save the GPS and inertial measurement unit (IMU) data of the capturing of images, this program gives an option to use the SLAM algorithm successfully even if the dataset has a low frame rate.},
	language = {en},
	number = {22},
	urldate = {2021-07-18},
	journal = {Sensors},
	author = {Kiss-Illés, Dániel and Barrado, Cristina and Salamí, Esther},
	month = nov,
	year = {2019},
	pages = {4973},
	file = {Kiss-Illés et al. - 2019 - GPS-SLAM An Augmentation of the ORB-SLAM Algorith.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\GFC4I6FH\\Kiss-Illés et al. - 2019 - GPS-SLAM An Augmentation of the ORB-SLAM Algorith.pdf:application/pdf},
}

@article{andersone_heterogeneous_2019,
	title = {Heterogeneous {Map} {Merging}: {State} of the {Art}},
	volume = {8},
	issn = {2218-6581},
	shorttitle = {Heterogeneous {Map} {Merging}},
	url = {https://www.mdpi.com/2218-6581/8/3/74},
	doi = {10.3390/robotics8030074},
	abstract = {Multi-robot mapping and environment modeling have several advantages that make it an attractive alternative to the mapping with a single robot: faster exploration, higher fault tolerance, richer data due to different sensors being used by different systems. However, the environment modeling with several robotic systems operating in the same area causes problems of higher-order—acquired knowledge fusion and synchronization over time, revealing the same environment properties using different sensors with different technical speciﬁcations. While the existing robot map and environment model merging techniques allow merging certain homogeneous maps, the possibility to use sensors of different physical nature and different mapping algorithms is limited. The resulting maps from robots with different speciﬁcations are heterogeneous, and even though some research on how to merge fundamentally different maps exists, it is limited to speciﬁc applications. This research reviews the state of the art in homogeneous and heterogeneous map merging and illustrates the main research challenges in the area. Six factors are identiﬁed that inﬂuence the outcome of map merging: (1) robotic platform hardware conﬁgurations, (2) map representation types, (3) mapping algorithms, (4) shared information between robots, (5) relative positioning information, (6) resulting global maps.},
	language = {en},
	number = {3},
	urldate = {2021-07-16},
	journal = {Robotics},
	author = {{Andersone}},
	month = aug,
	year = {2019},
	pages = {74},
	file = {Andersone - 2019 - Heterogeneous Map Merging State of the Art.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\ZDBS47KV\\Andersone - 2019 - Heterogeneous Map Merging State of the Art.pdf:application/pdf},
}

@article{campos_orb-slam3_2021,
	title = {{ORB}-{SLAM3}: {An} {Accurate} {Open}-{Source} {Library} for {Visual}, {Visual}-{Inertial} and {Multi}-{Map} {SLAM}},
	issn = {1552-3098, 1941-0468},
	shorttitle = {{ORB}-{SLAM3}},
	url = {http://arxiv.org/abs/2007.11898},
	doi = {10.1109/TRO.2021.3075644},
	abstract = {This paper presents ORB-SLAM3, the ﬁrst system able to perform visual, visual-inertial and multi-map SLAM with monocular, stereo and RGB-D cameras, using pin-hole and ﬁsheye lens models.},
	language = {en},
	urldate = {2021-07-16},
	journal = {IEEE Transactions on Robotics},
	author = {Campos, Carlos and Elvira, Richard and Rodríguez, Juan J. Gómez and Montiel, José M. M. and Tardós, Juan D.},
	year = {2021},
	note = {arXiv: 2007.11898},
	keywords = {Computer Science - Robotics},
	pages = {1--17},
	annote = {State-of-the-art SLAM solution that will be used in the thesis},
	file = {Campos et al. - 2021 - ORB-SLAM3 An Accurate Open-Source Library for Vis.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\RLGVHMN2\\Campos et al. - 2021 - ORB-SLAM3 An Accurate Open-Source Library for Vis.pdf:application/pdf},
}

@article{yu_review_2020,
	title = {A {Review} on {Map}-{Merging} {Methods} for {Typical} {Map} {Types} in {Multiple}-{Ground}-{Robot} {SLAM} {Solutions}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/23/6988},
	doi = {10.3390/s20236988},
	abstract = {When multiple robots are involved in the process of simultaneous localization and mapping (SLAM), a global map should be constructed by merging the local maps built by individual robots, so as to provide a better representation of the environment. Hence, the map-merging methods play a crucial rule in multi-robot systems and determine the performance of multi-robot SLAM. This paper looks into the key problem of map merging for multiple-ground-robot SLAM and reviews the typical map-merging methods for several important types of maps in SLAM applications: occupancy grid maps, feature-based maps, and topological maps. These map-merging approaches are classiﬁed based on their working mechanism or the type of features they deal with. The concepts and characteristics of these map-merging methods are elaborated in this review. The contents summarized in this paper provide insights and guidance for future multiple-ground-robot SLAM solutions.},
	language = {en},
	number = {23},
	urldate = {2021-07-12},
	journal = {Sensors},
	author = {Yu, Shuien and Fu, Chunyun and Gostar, Amirali K. and Hu, Minghui},
	month = dec,
	year = {2020},
	pages = {6988},
	annote = {Good overview of core subject of thesis.},
	file = {Yu et al. - 2020 - A Review on Map-Merging Methods for Typical Map Ty.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\JIAIUFHW\\Yu et al. - 2020 - A Review on Map-Merging Methods for Typical Map Ty.pdf:application/pdf},
}

@article{huang_fast_2020,
	title = {Fast {Reconstruction} of {3D} {Point} {Cloud} {Model} {Using} {Visual} {SLAM} on {Embedded} {UAV} {Development} {Platform}},
	volume = {12},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/12/20/3308},
	doi = {10.3390/rs12203308},
	abstract = {In recent years, the rapid development of unmanned aerial vehicle (UAV) technologies has made data acquisition increasingly convenient, and three-dimensional (3D) reconstruction has emerged as a popular subject of research in this context. These 3D models have many advantages, such as the ability to represent realistic scenes and a large amount of information. However, traditional 3D reconstruction methods are expensive, and require long and complex processing. As a result, they cannot rapidly respond when used in time-sensitive applications, e.g., those for such natural disasters as earthquakes, debris ﬂow, etc. Computer vision-based simultaneous localization and mapping (SLAM) along with hardware development based on embedded systems, can provide a solution to this problem. Based on an analysis of the principle and implementation of the visual SLAM algorithm, this study proposes a fast method to quickly reconstruct a dense 3D point cloud model on a UAV platform combined with an embedded graphics processing unit (GPU). The main contributions are as follows: (1) to resolve the contradiction between the resource limitations and the computational complexity of visual SLAM on UAV platforms, the technologies needed to compute resource allocation, communication between nodes, and data transmission and visualization in an embedded environment were investigated to achieve real-time data acquisition and processing. Visual monitoring to this end is also designed and implemented. (2) To solve the problem of time-consuming algorithmic processing, a corresponding parallel algorithm was designed and implemented based on the parallel programming framework of the compute uniﬁed device architecture (CUDA). (3) The visual odometer and methods of 3D “map” reconstruction were designed using under a monocular vision sensor to implement the prototype of the fast 3D reconstruction system. Based on preliminary results of the 3D modeling, the following was noted: (1) the proposed method was feasible. By combining UAV, SLAM, and parallel computing, a simple and eﬃcient 3D reconstruction model of an unknown area was obtained for speciﬁc applications. (2) The parallel SLAM algorithm used in this method improved the eﬃciency of the SLAM algorithm. On the one hand, the SLAM algorithm required 1/6 of the time taken by the structure-from-motion algorithm. On the other hand, the speedup obtained using the parallel SLAM algorithm based on the embedded GPU on our test platform was 7.55 × that of the serial algorithm. (3) The depth map results show that the eﬀective pixel with an error less than 15cm is close to 60\%.},
	language = {en},
	number = {20},
	urldate = {2021-06-25},
	journal = {Remote Sensing},
	author = {Huang, Fang and Yang, Hao and Tan, Xicheng and Peng, Shuying and Tao, Jian and Peng, Siyuan},
	month = oct,
	year = {2020},
	pages = {3308},
	file = {Huang et al. - 2020 - Fast Reconstruction of 3D Point Cloud Model Using .pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\K98N7684\\Huang et al. - 2020 - Fast Reconstruction of 3D Point Cloud Model Using .pdf:application/pdf},
}

@article{grisetti_tutorial_2010,
	title = {A {Tutorial} on {Graph}-{Based} {SLAM}},
	volume = {2},
	issn = {1939-1390},
	url = {http://ieeexplore.ieee.org/document/5681215/},
	doi = {10.1109/MITS.2010.939925},
	abstract = {Being able to build a map of the environment and to simultaneously localize within this map is an essential skill for mobile robots navigating in unknown environments in absence of external referencing systems such as GPS. This so-called simultaneous localization and mapping (SLAM) problem has been one of the most popular research topics in mobile robotics for the last two decades and efﬁcient approaches for solving this task have been proposed. One intuitive way of formulating SLAM is to use a graph whose nodes correspond to the poses of the robot at different points in time and whose edges represent constraints between the poses. The latter are obtained from observations of the environment or from movement actions carried out by the robot. Once such a graph is constructed, the map can be computed by ﬁnding the spatial conﬁguration of the nodes that is mostly consistent with the measurements modeled by the edges. In this paper, we provide an introductory description to the graph-based SLAM problem. Furthermore, we discuss a state-of-the-art solution that is based on least-squares error minimization and exploits the structure of the SLAM problems during optimization. The goal of this tutorial is to enable the reader to implement the proposed methods from scratch.},
	language = {en},
	number = {4},
	urldate = {2021-06-24},
	journal = {IEEE Intelligent Transportation Systems Magazine},
	author = {Grisetti, G and Kummerle, R and Stachniss, C and Burgard, W},
	year = {2010},
	pages = {31--43},
	file = {Grisetti et al. - 2010 - A Tutorial on Graph-Based SLAM.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\2IIK3F38\\Grisetti et al. - 2010 - A Tutorial on Graph-Based SLAM.pdf:application/pdf},
}

@article{grisetti_tutorial_2010-1,
	title = {A {Tutorial} on {Graph}-{Based} {SLAM}},
	volume = {2},
	issn = {1939-1390},
	url = {http://ieeexplore.ieee.org/document/5681215/},
	doi = {10.1109/MITS.2010.939925},
	abstract = {Being able to build a map of the environment and to simultaneously localize within this map is an essential skill for mobile robots navigating in unknown environments in absence of external referencing systems such as GPS. This so-called simultaneous localization and mapping (SLAM) problem has been one of the most popular research topics in mobile robotics for the last two decades and efﬁcient approaches for solving this task have been proposed. One intuitive way of formulating SLAM is to use a graph whose nodes correspond to the poses of the robot at different points in time and whose edges represent constraints between the poses. The latter are obtained from observations of the environment or from movement actions carried out by the robot. Once such a graph is constructed, the map can be computed by ﬁnding the spatial conﬁguration of the nodes that is mostly consistent with the measurements modeled by the edges. In this paper, we provide an introductory description to the graph-based SLAM problem. Furthermore, we discuss a state-of-the-art solution that is based on least-squares error minimization and exploits the structure of the SLAM problems during optimization. The goal of this tutorial is to enable the reader to implement the proposed methods from scratch.},
	language = {en},
	number = {4},
	urldate = {2021-06-23},
	journal = {IEEE Intelligent Transportation Systems Magazine},
	author = {Grisetti, G and Kummerle, R and Stachniss, C and Burgard, W},
	year = {2010},
	pages = {31--43},
	file = {Grisetti et al. - 2010 - A Tutorial on Graph-Based SLAM.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\AAIZAMUR\\Grisetti et al. - 2010 - A Tutorial on Graph-Based SLAM.pdf:application/pdf},
}

@misc{noauthor_adjustment_nodate,
	title = {Adjustment theory - {Lecture} {Notes}},
	file = {Adjustment theory - Lecture Notes.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\38ITVVPL\\Adjustment theory - Lecture Notes.pdf:application/pdf},
}

@phdthesis{guilarte_collaborative_nodate,
	title = {Collaborative {Localization} and {Mapping} with {Heterogeneous} {Depth} {Sensors}},
	author = {Guilarte, David},
	file = {Heterogeneous Depth Collaborative SLAM.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\L3XBTFF8\\Heterogeneous Depth Collaborative SLAM.pdf:application/pdf},
}

@inproceedings{dube_online_2017,
	address = {Vancouver, BC},
	title = {An online multi-robot {SLAM} system for {3D} {LiDARs}},
	isbn = {978-1-5386-2682-5},
	url = {http://ieeexplore.ieee.org/document/8202268/},
	doi = {10.1109/IROS.2017.8202268},
	abstract = {Using multiple cooperative robots is advantageous for time critical Search and Rescue (SaR) missions as they permit rapid exploration of the environment and provide higher redundancy than using a single robot. A considerable number of applications such as autonomous driving and disaster response could beneﬁt from merging mapping data from several agents. Online multi-robot localization and mapping has mainly been addressed for robots equipped with cameras or 2D LiDARs. However, in unstructured and ill-lighted real-life scenarios, a mapping system can potentially beneﬁt from a rich 3D geometric solution. In this work, we present an online localization and mapping system for multiple robots equipped with 3D LiDARs. This system is based on incremental sparse pose-graph optimization using sequential and place recognition constraints, the latter being identiﬁed using a 3D segment matching approach. The result is a uniﬁed representation of the world and relative robot trajectories. The complete system runs in real-time and is evaluated with two experiments in different environments: one urban and one disaster scenario. The system is available open source and easy-to-run demonstrations are publicly available.},
	language = {en},
	urldate = {2021-06-19},
	booktitle = {2017 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	publisher = {IEEE},
	author = {Dube, Renaud and Gawel, Abel and Sommer, Hannes and Nieto, Juan and Siegwart, Roland and Cadena, Cesar},
	month = sep,
	year = {2017},
	pages = {1004--1011},
	file = {Dube et al. - 2017 - An online multi-robot SLAM system for 3D LiDARs.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\SEA58LBD\\Dube et al. - 2017 - An online multi-robot SLAM system for 3D LiDARs.pdf:application/pdf},
}

@article{fox_kld-sampling_nodate,
	title = {{KLD}-{Sampling}: {Adaptive} {Particle} {Filters}},
	abstract = {Over the last years, particle ﬁlters have been applied with great success to a variety of state estimation problems. We present a statistical approach to increasing the efﬁciency of particle ﬁlters by adapting the size of sample sets on-the-ﬂy. The key idea of the KLD-sampling method is to bound the approximation error introduced by the sample-based representation of the particle ﬁlter. The name KLD-sampling is due to the fact that we measure the approximation error by the Kullback-Leibler distance. Our adaptation approach chooses a small number of samples if the density is focused on a small part of the state space, and it chooses a large number of samples if the state uncertainty is high. Both the implementation and computation overhead of this approach are small. Extensive experiments using mobile robot localization as a test application show that our approach yields drastic improvements over particle ﬁlters with ﬁxed sample set sizes and over a previously introduced adaptation technique.},
	language = {en},
	author = {Fox, Dieter},
	pages = {8},
	file = {Fox - KLD-Sampling Adaptive Particle Filters.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\SKTDJ747\\Fox - KLD-Sampling Adaptive Particle Filters.pdf:application/pdf},
}

@article{bot_graph-matching_2019,
	title = {A {Graph}-{Matching} {Approach} {To} {Indoor} {Localization} {Using} {A} {Mobile} {Device} {And} {A} {Reference} {BIM}},
	volume = {XLII-2/W13},
	issn = {2194-9034},
	url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W13/761/2019/},
	doi = {10.5194/isprs-archives-XLII-2-W13-761-2019},
	abstract = {The presented method provides for a possibility to perform graph-based indoor localization, by comparing the topological structure embedded in a mesh model to the topological structure of a semantically rich reference model, speciﬁcally a BIM. However different in nature and structure, both input sources can be converted to a graph of similar calibre, such that they can be tested for a match. After a match between both graphs is found, the current position of the actor within the mesh model can be translated to the room found in the graph. This room is now connected to a room within the reference graph, for which the semantics are stored in the BIM. Returning these to the actor, a location description can be formed.},
	language = {en},
	urldate = {2021-06-18},
	journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Bot, F. J. and Nourian, P. and Verbree, E.},
	month = jun,
	year = {2019},
	keywords = {Localization},
	pages = {761--767},
	file = {Bot et al. - 2019 - A GRAPH-MATCHING APPROACH TO INDOOR LOCALIZATION U.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\R43UDBXH\\Bot et al. - 2019 - A GRAPH-MATCHING APPROACH TO INDOOR LOCALIZATION U.pdf:application/pdf},
}

@article{fox_monte_nodate,
	title = {Monte {Carlo} {Localization}: {Efﬁcient} {Position} {Estimation} for {Mobile} {Robots}},
	abstract = {This paper presents a new algorithm for mobile robot localization, called Monte Carlo Localization (MCL). MCL is a version of Markov localization, a family of probabilistic approaches that have recently been applied with great practical success. However, previous approaches were either computationally cumbersome (such as grid-based approaches that represent the state space by high-resolution 3D grids), or had to resort to extremely coarse-grained resolutions. Our approach is computationally efﬁcient while retaining the ability to represent (almost) arbitrary distributions. MCL applies sampling-based methods for approximating probability distributions, in a way that places computation “where needed.” The number of samples is adapted on-line, thereby invoking large sample sets only when necessary. Empirical results illustrate that MCL yields improved accuracy while requiring an order of magnitude less computation when compared to previous approaches. It is also much easier to implement.},
	language = {en},
	author = {Fox, Dieter and Burgard, Wolfram and Dellaert, Frank and Thrun, Sebastian},
	keywords = {Localization},
	pages = {7},
	file = {Fox et al. - Monte Carlo Localization Efﬁcient Position Estima.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\2CWQ9WYP\\Fox et al. - Monte Carlo Localization Efﬁcient Position Estima.pdf:application/pdf},
}

@article{thrun_probabilistic_2002,
	title = {Probabilistic robotics},
	volume = {45},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/504729.504754},
	doi = {10.1145/504729.504754},
	abstract = {Planning and navigation algorithms exploit statistics gleaned from uncertain, imperfect real-world environments to guide robots toward their goals and around obstacles.},
	language = {en},
	number = {3},
	urldate = {2021-06-18},
	journal = {Communications of the ACM},
	author = {Thrun, Sebastian},
	month = mar,
	year = {2002},
	keywords = {Localization, SLAM, Statistics},
	pages = {52--57},
}

@article{zou_coslam_2013,
	title = {{CoSLAM}: {Collaborative} {Visual} {SLAM} in {Dynamic} {Environments}},
	volume = {35},
	issn = {0162-8828, 2160-9292},
	shorttitle = {{CoSLAM}},
	url = {http://ieeexplore.ieee.org/document/6193110/},
	doi = {10.1109/TPAMI.2012.104},
	abstract = {This paper studies the problem of vision-based simultaneous localization and mapping (SLAM) in dynamic environments with multiple cameras. These cameras move independently and can be mounted on different platforms. All cameras work together to build a global map, including 3D positions of static background points and trajectories of moving foreground points. We introduce inter-camera pose estimation and inter-camera mapping to deal with dynamic objects in the localization and mapping process. To further enhance the system robustness, we maintain the position uncertainty of each map point. To facilitate intercamera operations, we cluster cameras into groups according to their view overlap, and manage the split and merge of camera groups in real-time. Experimental results demonstrate that our system can work robustly in highly dynamic environments and produce more accurate results in static environments.},
	language = {en},
	number = {2},
	urldate = {2021-06-18},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Zou, Danping and Tan, Ping},
	month = feb,
	year = {2013},
	keywords = {Localization, CSLAM},
	pages = {354--366},
	file = {Zou and Tan - 2013 - CoSLAM Collaborative Visual SLAM in Dynamic Envir.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\B6XGS2ZK\\Zou and Tan - 2013 - CoSLAM Collaborative Visual SLAM in Dynamic Envir.pdf:application/pdf},
}

@article{willems_exploring_nodate,
	title = {Exploring a pure landmark-based approach for indoor localisation},
	abstract = {Humans interact more and more with their environment through technology, recent decades have seen a huge increase in the need for and availability Location-Based Services (LBS). Recently landmarks have gotten a renewed interest in the ﬁeld of LBS) , although already a quite old phenomenon. In both the outdoor and indoor environment they are being used to enrich existing services such as navigation, but not used as the basis for a technique or service. The indoor environment relies heavily on building speciﬁc and less-scalable sensorbased localisation techniques (such as Wi-Fi and Bluetooth), alternatives to sensorbased are becoming a necessity and would be a welcome addition. The exploration and development of landmark-based approaches for indoor localisation is something that can extend the ﬁeld of geomatics and LBS. This research investigates if a pure landmark-based approach works for indoor localisation and which characteristics of landmarks can be exploited. This is achieved by developing a conceptual framework that explores how a landmark-based indoor localisation would work from an artiﬁcial point of view. A Minimal Viable Product (MPV) is implemented to evaluate if a landmark-based approach works and what needs to be improved or considered in future studies Starting from an artiﬁcial test case, the MPV to achieve indoor localisation is implementing and evaluated using a manually digitised real-world and more complex test case. The fundamental principle of landmark-based localisation is that through the observation of landmarks within the (indoor) environment a user’s location is obtained because the visibility and location of landmarks are known. The workﬂow to go from an observation to a location is by 1) calculating the visibility/isovist area of each landmark, 2) interpret the observations into a combination of landmarks, 3) intersect the visibility of all landmarks in the observation, 4) reﬁne the location based on relative landmark constellations, and 5) follow-up with questions on potentially visible landmarks to improve location further One of the key giveaways of this research is that approach for indoor localisation a landmark-based is feasible, principles and techniques exist (or are being developed), it is only a matter of setting them up in the right order and format them to work, and connect input with the researched process and use them for LBS driven applications. Future work on the subject of landmark-based localisation and LBS is connecting with existing spatial standards, extend the principles into the 3rd dimension, and integrate more aspects of landmark salience.},
	language = {en},
	author = {Willems, Oscar Timothy},
	keywords = {Localization},
	pages = {89},
	file = {Willems - Exploring a pure landmark-based approach for indoo.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\EA5TIW5A\\Willems - Exploring a pure landmark-based approach for indoo.pdf:application/pdf},
}

@article{ouyang_collaborative_2021,
	title = {A {Collaborative} {Visual} {SLAM} {Framework} for {Service} {Robots}},
	url = {http://arxiv.org/abs/2102.03228},
	abstract = {With the rapid deployment of service robots, a method should be established to allow multiple robots to work in the same place to collaborate and share the spatial information. To this end, we present a collaborative visual simultaneous localization and mapping (SLAM) framework particularly designed for service robot scenarios. With an edge server maintaining a map database and performing global optimization, each robot can register to an existing map, update the map, or build new maps, all with a uniﬁed interface and low computation and memory cost. To enable real-time information sharing, we design a simple but effective communication pipeline and a novel landmark retrieval method to augment each client’s local map with nearby landmarks from the server. The framework is general enough to support both RGB-D and monocular cameras, as well as robots with multiple cameras, taking the rigid constraints between cameras into consideration. The proposed framework has been fully implemented and veriﬁed with public datasets and live experiments.},
	language = {en},
	urldate = {2021-06-18},
	journal = {arXiv:2102.03228 [cs]},
	author = {Ouyang, Ming and Shi, Xuesong and Wang, Yujie and Tian, Yuxin and Shen, Yingzhe and Wang, Dawei and Wang, Peng and Cao, Zhiqiang},
	month = mar,
	year = {2021},
	note = {arXiv: 2102.03228},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics, CSLAM},
	file = {Ouyang et al. - 2021 - A Collaborative Visual SLAM Framework for Service .pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\CKRX9BZJ\\Ouyang et al. - 2021 - A Collaborative Visual SLAM Framework for Service .pdf:application/pdf},
}

@article{thrun_probabilistic_2002-1,
	title = {Probabilistic robotics},
	volume = {45},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/504729.504754},
	doi = {10.1145/504729.504754},
	abstract = {Planning and navigation algorithms exploit statistics gleaned from uncertain, imperfect real-world environments to guide robots toward their goals and around obstacles.},
	language = {en},
	number = {3},
	urldate = {2021-06-18},
	journal = {Communications of the ACM},
	author = {Thrun, Sebastian},
	month = mar,
	year = {2002},
	pages = {52--57},
	file = {Thrun - 2002 - Probabilistic robotics.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\UFZARZLK\\Thrun - 2002 - Probabilistic robotics.pdf:application/pdf},
}

@book{barfoot_state_2017,
	address = {Cambridge},
	title = {State {Estimation} for {Robotics}},
	isbn = {978-1-316-67152-8},
	url = {http://ebooks.cambridge.org/ref/id/CBO9781316671528},
	language = {en},
	urldate = {2021-06-18},
	publisher = {Cambridge University Press},
	author = {Barfoot, Timothy D.},
	year = {2017},
	doi = {10.1017/9781316671528},
	file = {Barfoot - 2017 - State Estimation for Robotics.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\U77BQDL8\\Barfoot - 2017 - State Estimation for Robotics.pdf:application/pdf},
}

@article{hiller_learning_2020,
	title = {Learning {Topometric} {Semantic} {Maps} from {Occupancy} {Grids}},
	url = {http://arxiv.org/abs/2001.03676},
	abstract = {Today's mobile robots are expected to operate in complex environments they share with humans. To allow intuitive human-robot collaboration, robots require a human-like understanding of their surroundings in terms of semantically classified instances. In this paper, we propose a new approach for deriving such instance-based semantic maps purely from occupancy grids. We employ a combination of deep learning techniques to detect, segment and extract door hypotheses from a random-sized map. The extraction is followed by a post-processing chain to further increase the accuracy of our approach, as well as place categorization for the three classes room, door and corridor. All detected and classified entities are described as instances specified in a common coordinate system, while a topological map is derived to capture their spatial links. To train our two neural networks used for detection and map segmentation, we contribute a simulator that automatically creates and annotates the required training data. We further provide insight into which features are learned to detect doorways, and how the simulated training data can be augmented to train networks for the direct application on real-world grid maps. We evaluate our approach on several publicly available real-world data sets. Even though the used networks are solely trained on simulated data, our approach demonstrates high robustness and effectiveness in various real-world indoor environments.},
	urldate = {2021-11-09},
	journal = {arXiv:2001.03676 [cs]},
	author = {Hiller, Markus and Qiu, Chen and Particke, Florian and Hofmann, Christian and Thielecke, Jörn},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.03676},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics, Important},
	annote = {Comment: Presented at the 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	annote = {Important
 },
	file = {arXiv Fulltext PDF:C\:\\Users\\max.van.schendel\\Zotero\\storage\\35QDGAWH\\Hiller et al. - 2020 - Learning Topometric Semantic Maps from Occupancy G.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\VELH89AA\\2001.html:text/html},
}

@article{bonanni_3-d_2017,
	title = {3-{D} {Map} {Merging} on {Pose} {Graphs}},
	volume = {2},
	issn = {2377-3766, 2377-3774},
	url = {https://ieeexplore.ieee.org/document/7822998/},
	doi = {10.1109/LRA.2017.2655139},
	abstract = {In this paper, we propose an approach for merging 3D maps represented as pose graphs of point clouds. Our method can effectively deal with typical distortions affecting SLAMgenerated maps. Traditional map merging techniques that use a single rigid body transformation to relate the reference frames of different maps. Instead, our approach achieves more accurate results by eliminating the inconsistencies resulting from distortions affecting the inputs, and can succeed in those situations where traditional approaches fail for substantial deformations. The core idea behind our solution is to localize the robot in a reference map by using the data from another map as observations. We validated our approach on publicly available datasets, and provide quantitative results that conﬁrm its effectiveness on challenging instances of the merging problem.},
	language = {en},
	number = {2},
	urldate = {2021-11-09},
	journal = {IEEE Robotics and Automation Letters},
	author = {Bonanni, Taigo Maria and Della Corte, Bartolomeo and Grisetti, Giorgio},
	month = apr,
	year = {2017},
	pages = {1031--1038},
	file = {Bonanni et al. - 2017 - 3-D Map Merging on Pose Graphs.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\M3PKKZJT\\Bonanni et al. - 2017 - 3-D Map Merging on Pose Graphs.pdf:application/pdf},
}

@inproceedings{cowley_rapid_2011,
	address = {Shanghai, China},
	title = {Rapid multi-robot exploration with topometric maps},
	isbn = {978-1-61284-386-5},
	url = {http://ieeexplore.ieee.org/document/5980403/},
	doi = {10.1109/ICRA.2011.5980403},
	abstract = {Multi-robot map building has advanced to the point where high quality occupancy grid data may be collected by multiple robots collaborating with only intermittent connectivity. However, the tasking of these agents to most efﬁciently build the map is a problem that has seen less attention. Unfamiliar, highly cluttered environments can confound exploration strategies that rely solely on occupancy grid frontier identiﬁcation or even semantic classiﬁcation methods keyed on geometric features. To reason about partial maps of novel, highly cluttered locations, hypotheses about signiﬁcant structure in the disposition of free space may be used to guide exploration task assignment. A parsing of map data into places with semantic signiﬁcance to the exploration task provides a foundation from which one may infer an efﬁcient exploration strategy.},
	language = {en},
	urldate = {2021-11-09},
	booktitle = {2011 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	publisher = {IEEE},
	author = {Cowley, Anthony and Taylor, Camillo J. and Southall, Ben},
	month = may,
	year = {2011},
	pages = {1044--1049},
	annote = {Does not provide a strategy for map merging},
	file = {Cowley et al. - 2011 - Rapid multi-robot exploration with topometric maps.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\8SNGMJQU\\Cowley et al. - 2011 - Rapid multi-robot exploration with topometric maps.pdf:application/pdf},
}

@article{gholamishahbandi_2d_2019,
	title = {{2D} map alignment with region decomposition},
	volume = {43},
	issn = {0929-5593, 1573-7527},
	url = {http://link.springer.com/10.1007/s10514-018-9785-7},
	doi = {10.1007/s10514-018-9785-7},
	abstract = {In many applications of autonomous mobile robots the following problem is encountered. Two maps of the same environment are available, one a prior map and the other a sensor map built by the robot. To beneﬁt from all available information in both maps, the robot must ﬁnd the correct alignment between the two maps. There exist many approaches to address this challenge, however, most of the previous methods rely on assumptions such as similar modalities of the maps, same scale, or existence of an initial guess for the alignment. In this work we propose a decomposition-based method for 2D spatial map alignment which does not rely on those assumptions. Our proposed method is validated and compared with other approaches, including generic data association approaches and map alignment algorithms. Real world examples of four different environments with thirty six sensor maps and four layout maps are used for this analysis. The maps, along with an implementation of the method, are made publicly available online.},
	language = {en},
	number = {5},
	urldate = {2021-11-09},
	journal = {Autonomous Robots},
	author = {Gholami Shahbandi, Saeed and Magnusson, Martin},
	month = jun,
	year = {2019},
	pages = {1117--1136},
	annote = {Merges robot map with prior map instead of pure map merging},
	file = {Gholami Shahbandi and Magnusson - 2019 - 2D map alignment with region decomposition.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\HE4VVLU3\\Gholami Shahbandi and Magnusson - 2019 - 2D map alignment with region decomposition.pdf:application/pdf},
}

@article{shahbandi_nonlinear_2018,
	title = {Nonlinear {Optimization} of {Multimodal} {Two}-{Dimensional} {Map} {Alignment} {With} {Application} to {Prior} {Knowledge} {Transfer}},
	volume = {3},
	issn = {2377-3766},
	doi = {10.1109/LRA.2018.2806439},
	abstract = {We propose a method based on a nonlinear transformation for nonrigid alignment of maps of different modalities, exemplified with matching partial and deformed two-dimensional maps to layout maps. For two types of indoor environments, over a dataset of 40 maps, we have compared the method to state-of-the-art map matching and nonrigid image registration methods and demonstrate a success rate of 80.41\% and a mean point-to-point alignment error of 1.78 m, compared to 31.9\% and 10.7 m for the best alternative method. We also propose a fitness measure that can quite reliably detect bad alignments. Finally, we show a use case of transferring prior knowledge (labels/segmentation), demonstrating that map segmentation is more consistent when transferred from an aligned layout map than when operating directly on partial maps (95.97\% vs. 81.56\%).},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Shahbandi, Saeed Gholami and Magnusson, Martin and Iagnemma, Karl},
	month = jul,
	year = {2018},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Image registration, Layout, Mapping, Optimization, Robot sensing systems, Strain, Two dimensional displays},
	pages = {2040--2047},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\max.van.schendel\\Zotero\\storage\\5I9SNCJR\\8292790.html:text/html;Submitted Version:C\:\\Users\\max.van.schendel\\Zotero\\storage\\62RL583Z\\Shahbandi et al. - 2018 - Nonlinear Optimization of Multimodal Two-Dimension.pdf:application/pdf},
}

@inproceedings{rincon_map_2019,
	title = {Map {Merging} of {Oriented} {Topological} {Semantic} {Maps}},
	doi = {10.1109/MRS.2019.8901093},
	abstract = {In this paper we propose a solution for the problem of merging together partial spatial models relying on our recently introduced Oriented Topological Semantic Maps (OTSM). This problem arises when a group of robots cooperatively explore an environment, and each one independently builds a partial map that must be combined with the others into a full map. Our methodology is inspired by the Warrington's Object Recognition Model, a cognitive model hypothesizing two post-sensory categorical stages working together for object recognition. Accordingly, we use two stages to compare different maps and match them together based on their mutual resemblance. Our method is complemented by a scoring system to measure the likelihood that two vertices in different OTSMs correspond to the same vertex, despite possible errors in labeling, orientation, or topological structure. Our methodology is validated in a simulation informed by an ongoing real robot implementation, thus allowing us to perform various experiments with carefully controlled error sources.},
	booktitle = {2019 {International} {Symposium} on {Multi}-{Robot} and {Multi}-{Agent} {Systems} ({MRS})},
	author = {Rincon, Jose Luis Susa and Carpin, Stefano},
	month = aug,
	year = {2019},
	keywords = {Measurement, Robot sensing systems, Merging, Object recognition, Robot kinematics, Semantics},
	pages = {202--208},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\max.van.schendel\\Zotero\\storage\\SCLTUZBH\\8901093.html:text/html},
}

@article{he_hierarchical_2021,
	title = {Hierarchical topometric representation of {3D} robotic maps},
	volume = {45},
	issn = {0929-5593, 1573-7527},
	url = {https://link.springer.com/10.1007/s10514-021-09991-8},
	doi = {10.1007/s10514-021-09991-8},
	abstract = {In this paper, we propose a method for generating a hierarchical, volumetric topological map from 3D point clouds. There are three basic hierarchical levels in our map: stor ey − r egion − volume. The advantages of our method are reﬂected in both input and output. In terms of input, we accept multi-storey point clouds and building structures with sloping roofs or ceilings. In terms of output, we can generate results with metric information of different dimensionality, that are suitable for different robotics applications. The algorithm generates the volumetric representation by generating volumes from a 3D voxel occupancy map. We then add passages (connections between volumes), combine small volumes into a big r egion and use a 2D segmentation method for better topological representation. We evaluate our method on several freely available datasets. The experiments highlight the advantages of our approach.},
	language = {en},
	number = {5},
	urldate = {2021-11-09},
	journal = {Autonomous Robots},
	author = {He, Zhenpeng and Sun, Hao and Hou, Jiawei and Ha, Yajun and Schwertfeger, Sören},
	month = jun,
	year = {2021},
	pages = {755--771},
	file = {He et al. - 2021 - Hierarchical topometric representation of 3D robot.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\3JJKCS66\\He et al. - 2021 - Hierarchical topometric representation of 3D robot.pdf:application/pdf;He2021_Article_HierarchicalTopometricRepresen.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\L6NFNSHS\\He2021_Article_HierarchicalTopometricRepresen.pdf:application/pdf},
}

@article{ochmann_towards_2014,
	title = {Towards the {Extraction} of {Hierarchical} {Building} {Descriptions} from {3D} {Indoor} {Scans}},
	abstract = {We present a new method for the hierarchical decomposition of 3D indoor scans and the subsequent generation of an according hierarchical graph-based building descriptor. The hierarchy consists of four basic levels with according entities, building - storey - room - object. All entities are represented as attributed nodes in a graph and are linked to the upper level entity they are located in. Additionally, nodes of the same level are linked depending on their spatial and topological relationship. The hierarchical description enables easy navigation in the formerly unstructured data, measurement takings, as well as carrying out retrieval tasks that incorporate geometric, topological, and also functional building properties describing e.g. the designated use of single rooms according to the objects it contains. In contrast to previous methods which either focus on the segmentation into rooms or on the recognition of indoor objects, our holistic approach incorporates a rather large spectrum of entities on different semantic levels that are inherent to 3D building representations. In our evaluation we show the feasibility of our method for extraction of hierarchical building descriptions for various tasks using synthetic as well as real world data.},
	language = {en},
	author = {Ochmann, S and Vock, R and Wessel, R and Klein, R},
	year = {2014},
	pages = {8},
	file = {Ochmann et al. - Towards the Extraction of Hierarchical Building De.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\GEXCYMZ5\\Ochmann et al. - Towards the Extraction of Hierarchical Building De.pdf:application/pdf;Ochmann et al. - Towards the Extraction of Hierarchical Building De.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\W7VJ93A4\\Ochmann et al. - Towards the Extraction of Hierarchical Building De.pdf:application/pdf},
}

@article{kuipers_spatial_2000,
	title = {The {Spatial} {Semantic} {Hierarchy}},
	volume = {119},
	issn = {0004-3702},
	url = {https://www.sciencedirect.com/science/article/pii/S0004370200000175},
	doi = {10.1016/S0004-3702(00)00017-5},
	abstract = {The Spatial Semantic Hierarchy is a model of knowledge of large-scale space consisting of multiple interacting representations, both qualitative and quantitative. The SSH is inspired by the properties of the human cognitive map, and is intended to serve both as a model of the human cognitive map and as a method for robot exploration and map-building. The multiple levels of the SSH express states of partial knowledge, and thus enable the human or robotic agent to deal robustly with uncertainty during both learning and problem-solving. The control level represents useful patterns of sensorimotor interaction with the world in the form of trajectory-following and hill-climbing control laws leading to locally distinctive states. Local geometric maps in local frames of reference can be constructed at the control level to serve as observers for control laws in particular neighborhoods. The causal level abstracts continuous behavior among distinctive states into a discrete model consisting of states linked by actions. The topological level introduces the external ontology of places, paths and regions by abduction to explain the observed pattern of states and actions at the causal level. Quantitative knowledge at the control, causal and topological levels supports a “patchwork map” of local geometric frames of reference linked by causal and topological connections. The patchwork map can be merged into a single global frame of reference at the metrical level when sufficient information and computational resources are available. We describe the assumptions and guarantees behind the generality of the SSH across environments and sensorimotor systems. Evidence is presented from several partial implementations of the SSH on simulated and physical robots.},
	language = {en},
	number = {1},
	urldate = {2021-11-09},
	journal = {Artificial Intelligence},
	author = {Kuipers, Benjamin},
	month = may,
	year = {2000},
	keywords = {Cognitive map, Map learning, Qualitative reasoning, Robot exploration, Spatial reasoning},
	pages = {191--233},
	file = {Kuipers - 2000 - The Spatial Semantic Hierarchy.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\4MMYB53J\\Kuipers - 2000 - The Spatial Semantic Hierarchy.pdf:application/pdf},
}

@article{chen_advanced_2020,
	title = {Advanced mapping robot and high-resolution dataset},
	volume = {131},
	issn = {0921-8890},
	url = {https://www.sciencedirect.com/science/article/pii/S0921889020303997},
	doi = {10.1016/j.robot.2020.103559},
	abstract = {This paper presents a fully hardware synchronized mapping robot with support for a hardware synchronized external tracking system, for super-precise timing and localization. Nine high-resolution cameras and two 32-beam 3D Lidars were used along with a professional, static 3D scanner for ground truth map collection. With all the sensors calibrated on the mapping robot, three datasets are collected to evaluate the performance of mapping algorithms within a room and between rooms. Based on these datasets we generate maps and trajectory data, which is then fed into evaluation algorithms. We provide the datasets for download and the mapping and evaluation procedures are made in a very easily reproducible manner for maximum comparability. We have also conducted a survey on available robotics-related datasets and compiled a big table with those datasets and a number of properties of them.},
	language = {en},
	urldate = {2021-11-09},
	journal = {Robotics and Autonomous Systems},
	author = {Chen, Hongyu and Yang, Zhijie and Zhao, Xiting and Weng, Guangyuan and Wan, Haochuan and Luo, Jianwen and Ye, Xiaoya and Zhao, Zehao and He, Zhenpeng and Shen, Yongxia and Schwertfeger, Sören},
	month = sep,
	year = {2020},
	keywords = {Mobile robot, Robotic datasets, Sensor calibration, Sensor synchronization, Simultaneous Localization and Mapping (SLAM)},
	pages = {103559},
	file = {ScienceDirect Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\IYLE8W49\\S0921889020303997.html:text/html;Submitted Version:C\:\\Users\\max.van.schendel\\Zotero\\storage\\E5LITJJP\\Chen et al. - 2020 - Advanced mapping robot and high-resolution dataset.pdf:application/pdf},
}

@inproceedings{badino_real-time_2012-3,
	title = {Real-time topometric localization},
	doi = {10.1109/ICRA.2012.6224716},
	abstract = {Autonomous vehicles must be capable of localizing even in GPS denied situations. In this paper, we propose a real-time method to localize a vehicle along a route using visual imagery or range information. Our approach is an implementation of topometric localization, which combines the robustness of topological localization with the geometric accuracy of metric methods. We construct a map by navigating the route using a GPS-equipped vehicle and building a compact database of simple visual and 3D features. We then localize using a Bayesian filter to match sequences of visual or range measurements to the database. The algorithm is reliable across wide environmental changes, including lighting differences, seasonal variations, and occlusions, achieving an average localization accuracy of 1 m over an 8 km route. The method converges correctly even with wrong initial position estimates solving the kidnapped robot problem.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Badino, Hernán and Huber, Daniel and Kanade, Takeo},
	month = may,
	year = {2012},
	note = {ISSN: 1050-4729},
	keywords = {Databases, Feature extraction, Global Positioning System, Measurement, Probability density function, Vehicles, Visualization},
	pages = {1635--1642},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\max.van.schendel\\Zotero\\storage\\87QCLBWM\\6224716.html:text/html;Submitted Version:C\:\\Users\\max.van.schendel\\Zotero\\storage\\RAAEEF6V\\Badino et al. - 2012 - Real-time topometric localization.pdf:application/pdf},
}

@inproceedings{rincon_map_2019-1,
	address = {New Brunswick, NJ, USA},
	title = {Map {Merging} of {Oriented} {Topological} {Semantic} {Maps}},
	isbn = {978-1-72812-876-4},
	url = {https://ieeexplore.ieee.org/document/8901093/},
	doi = {10.1109/MRS.2019.8901093},
	abstract = {In this paper we propose a solution for the problem of merging together partial spatial models relying on our recently introduced Oriented Topological Semantic Maps (OTSM). This problem arises when a group of robots cooperatively explore an environment, and each one independently builds a partial map that must be combined with the others into a full map. Our methodology is inspired by the Warrington’s Object Recognition Model, a cognitive model hypothesizing two post-sensory categorical stages working together for object recognition. Accordingly, we use two stages to compare different maps and match them together based on their mutual resemblance. Our method is complemented by a scoring system to measure the likelihood that two vertices in different OTSMs correspond to the same vertex, despite possible errors in labeling, orientation, or topological structure. Our methodology is validated in a simulation informed by an ongoing real robot implementation, thus allowing us to perform various experiments with carefully controlled error sources.},
	language = {en},
	urldate = {2021-11-10},
	booktitle = {2019 {International} {Symposium} on {Multi}-{Robot} and {Multi}-{Agent} {Systems} ({MRS})},
	publisher = {IEEE},
	author = {Rincon, Jose Luis Susa and Carpin, Stefano},
	month = aug,
	year = {2019},
	pages = {202--208},
	file = {mrs2019.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\JW3BF34Z\\mrs2019.pdf:application/pdf},
}

@article{huang_topological_2005,
	title = {Topological {Map} {Merging}},
	volume = {24},
	issn = {0278-3649, 1741-3176},
	url = {http://journals.sagepub.com/doi/10.1177/0278364905056348},
	doi = {10.1177/0278364905056348},
	abstract = {When multiple robots cooperatively explore an environment, maps from individual robots must be merged to produce a single globally consistent map. This is a challenging problem when the robots do not have a common reference frame or global positioning. In this paper, we describe an algorithm for merging embedded topological maps. Topological maps provide a concise description of the navigability of an environment, and, with measurements easily collected during exploration, the vertices of the map can be embedded in a metric space. Our algorithm uses both the structure and the geometry of topological maps to determine the best correspondence between maps with single or multiple overlapping regions. Experiments with simulated and real-world data demonstrate the efﬁcacy of our algorithm.},
	language = {en},
	number = {8},
	urldate = {2021-11-29},
	journal = {The International Journal of Robotics Research},
	author = {Huang, Wesley H. and Beevers, Kristopher R.},
	month = aug,
	year = {2005},
	pages = {601--613},
	annote = {Looks very promising but as of yet only in 2D with manually generated maps.},
	file = {10.1.1.120.2705.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\QVSC9E7A\\10.1.1.120.2705.pdf:application/pdf;Huang and Beevers - 2005 - Topological Map Merging.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\2K283KTW\\Huang and Beevers - 2005 - Topological Map Merging.pdf:application/pdf},
}

@article{saeedi_group_2014,
	title = {Group {Mapping}: {A} {Topological} {Approach} to {Map} {Merging} for {Multiple} {Robots}},
	volume = {21},
	issn = {1070-9932},
	shorttitle = {Group {Mapping}},
	url = {http://ieeexplore.ieee.org/document/6811207/},
	doi = {10.1109/MRA.2014.2304091},
	language = {en},
	number = {2},
	urldate = {2021-11-29},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Saeedi, Sajad and Paull, Liam and Trentini, Michael and Seto, Mae and Li, Howard},
	month = jun,
	year = {2014},
	pages = {60--72},
	file = {Saeedi et al. - 2014 - Group Mapping A Topological Approach to Map Mergi.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\76UTEQ9V\\Saeedi et al. - 2014 - Group Mapping A Topological Approach to Map Mergi.pdf:application/pdf},
}

@article{gorte_navigation_2019,
	title = {{NAVIGATION} {IN} {INDOOR} {VOXEL} {MODELS}},
	volume = {IV-2/W5},
	issn = {2194-9050},
	url = {https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/IV-2-W5/279/2019/},
	doi = {10.5194/isprs-annals-IV-2-W5-279-2019},
	abstract = {The paper proposes to use voxel models of building interiors to perform indoor navigation. The algorithms can be purely geometrical, not relying on semantic information about different building elements, such as floors, walls, stairways etc. Therefore, it is possible to use voxel models from different data sources, in addition to vector-to-raster conversions. The paper demonstrates this on the basis of tree different input types: hand measurements, point clouds and images of floorplans. On the basis of these models, the paper shows how to determine the navigable space in a voxel model for a pedestrian actor, and how to compute paths from arbitrary sources to specified destinations.},
	language = {en},
	urldate = {2021-12-06},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Gorte, B. and Zlatanova, S. and Fadli, F.},
	month = may,
	year = {2019},
	pages = {279--283},
	file = {Gorte et al. - 2019 - NAVIGATION IN INDOOR VOXEL MODELS.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\XPTPMFTE\\Gorte et al. - 2019 - NAVIGATION IN INDOOR VOXEL MODELS.pdf:application/pdf},
}

@article{thrun_probabilistic_2001,
	title = {A {Probabilistic} {On}-{Line} {Mapping} {Algorithm} for {Teams} of {Mobile} {Robots}},
	volume = {20},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/02783640122067435},
	doi = {10.1177/02783640122067435},
	abstract = {An efficient probabilistic algorithm for the concurrent mapping and localization problem that arises in mobile robotics is presented. The algorithm addresses the problem in which a team of robots builds a map on-line while simultaneously accommodating errors in the robots’ odometry. At the core of the algorithm is a technique that combines fast maximum likelihood map growing with a Monte Carlo localizer that uses particle representations. The combination of both yields an on-line algorithm that can cope with large odometric errors typically found when mapping environments with cycles. The algorithm can be implemented in a distributed manner on multiple robot platforms, enabling a team of robots to cooperatively generate a single map of their environment. Finally, an extension is described for acquiring three-dimensional maps, which capture the structure and visual appearance of indoor environments in three dimensions.},
	language = {en},
	number = {5},
	urldate = {2021-12-21},
	journal = {The International Journal of Robotics Research},
	author = {Thrun, Sebastian},
	month = may,
	year = {2001},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {localization, map acquisition, mobile robotics, multi-robot systems, robotic exploration, three-dimensional modeling},
	pages = {335--363},
	file = {SAGE PDF Full Text:C\:\\Users\\max.van.schendel\\Zotero\\storage\\WRGDCVKP\\Thrun - 2001 - A Probabilistic On-Line Mapping Algorithm for Team.pdf:application/pdf},
}

@article{elfes_occupancy_1990,
	title = {Occupancy {Grids}: {A} {Stochastic} {Spatial} {Representation} for {Active} {Robot} {Perception}},
	shorttitle = {Occupancy {Grids}},
	url = {http://arxiv.org/abs/1304.1098},
	abstract = {In this paper we provide an overview of a new framework for robot perception, real-world modelling, and navigation that uses a stochastic tesselated representation of spatial information called the Occupancy Grid. The Occupancy Grid is a multi-dimensional random field model that maintains probabilistic estimates of the occupancy state of each cell in a spatial lattice. Bayesian estimation mechanisms employing stochastic sensor models allow incremental updating of the Occupancy Grid using multi-view, multi-sensor data, composition of multiple maps, decision-making, and incorporation of robot and sensor position uncertainty. We present the underlying stochastic formulation of the Occupancy Grid framework, and discuss its application to a variety of robotic tusks. These include range-based mapping, multi-sensor integration, path-planning and obstacle avoidance, handling of robot position uncertainty, incorporation of pre-compiled maps, recovery of geometric representations, and other related problems. The experimental results show that the Occupancy Grid approach generates dense world models, is robust under sensor uncertainty and errors, and allows explicit handling of uncertainty. It supports the development of robust and agile sensor interpretation methods, incremental discovery procedures, and composition of information from multiple sources. Furthermore, the results illustrate that robotic tasks can be addressed through operations performed di- rectly on the Occupancy Grid, and that these operations have strong parallels to operations performed in the image processing domain.},
	urldate = {2021-12-21},
	journal = {arXiv:1304.1098 [cs]},
	author = {Elfes, A.},
	year = {1990},
	note = {arXiv: 1304.1098},
	keywords = {Computer Science - Robotics, Computer Science - Artificial Intelligence},
	annote = {Comment: Appears in Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence (UAI1990)},
	file = {arXiv Fulltext PDF:C\:\\Users\\max.van.schendel\\Zotero\\storage\\MVDIKRYC\\Elfes - 2013 - Occupancy Grids A Stochastic Spatial Representati.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\YETBAUZN\\1304.html:text/html},
}

@inproceedings{simhon_global_1998,
	title = {A global topological map formed by local metric maps},
	volume = {3},
	doi = {10.1109/IROS.1998.724844},
	abstract = {We describe a method of mapping large scale static environments using a hybrid topological-metric model. A global map is formed from a set of local maps organized in a topological structure. Each local map contains quantitative environment information using a local reference frame. They are denoted as islands of reliability because they provide accurate metric information of the environment. The mapping problem then becomes where to place the islands of reliability and to what extent should they cover the environment. This is accomplished by defining the placement criteria in terms of the task the islands of reliability portray.},
	booktitle = {Proceedings. 1998 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}. {Innovations} in {Theory}, {Practice} and {Applications} ({Cat}. {No}.{98CH36190})},
	author = {Simhon, S. and Dudek, G.},
	month = oct,
	year = {1998},
	keywords = {Feature extraction, Robot sensing systems, Robot kinematics, Calibration, Data mining, Extraterrestrial measurements, Large-scale systems, Orbital robotics, Solid modeling, Sonar measurements},
	pages = {1708--1714 vol.3},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\max.van.schendel\\Zotero\\storage\\NW56CMFL\\724844.html:text/html;Submitted Version:C\:\\Users\\max.van.schendel\\Zotero\\storage\\8FXCG34N\\Simhon and Dudek - 1998 - A global topological map formed by local metric ma.pdf:application/pdf},
}

@article{carpin_map_2005,
	title = {On {Map} {Merging}},
	volume = {53},
	journal = {International Journal of Robotics and Autonomous Systems},
	author = {Carpin, Stefano and Birk, Andreas and Jucikas, Victoras},
	year = {2005},
	pages = {1--14},
}

@article{carpin_map_2005-1,
	title = {On map merging},
	volume = {53},
	issn = {09218890},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0921889005001041},
	doi = {10.1016/j.robot.2005.07.001},
	abstract = {We illustrate our experience in developing and implementing algorithms for map merging, i.e., the problem of fusing two or more partial maps without common reference frames into one large global map. The partial maps may for example be acquired by multiple robots, or during several runs of a single robot from varying starting positions. Our work deals with low quality maps based on probabilistic grids, motivated by the goal to develop multiple mobile platforms to be used in rescue environments. Several contributions to map merging are presented. First of all, we address map merging using a motion planning algorithm. The merging process can be done by rotating and translating the partial maps until similar regions overlap. Second, a motion planning algorithm is presented which is particular suited for this task. Third, a special metric is presented which guides the motion planning algorithm towards the goal of optimally overlapping partial maps. Results with our approach are presented based on data gathered from real robots developed for the RoboCupRescue real robot league.},
	language = {en},
	number = {1},
	urldate = {2021-12-21},
	journal = {Robotics and Autonomous Systems},
	author = {Carpin, Stefano and Birk, Andreas and Jucikas, Viktoras},
	month = oct,
	year = {2005},
	pages = {1--14},
	file = {Carpin et al. - 2005 - On map merging.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\X42TL7AU\\Carpin et al. - 2005 - On map merging.pdf:application/pdf},
}

@inproceedings{konolige_map_2003,
	address = {Las Vegas, Nevada, USA},
	title = {Map merging for distributed robot navigation},
	volume = {1},
	isbn = {978-0-7803-7860-5},
	url = {http://ieeexplore.ieee.org/document/1250630/},
	doi = {10.1109/IROS.2003.1250630},
	abstract = {A set of robots mapping an area can potentially combine their information to produce a distributed map more efficiently than a single robot alone. We describe a general framework for distributed map building in the presence of uncertain communication. Within this framework, we then present a technical solution to the key decision problem of determining relative location within partial maps.},
	language = {en},
	urldate = {2021-12-21},
	booktitle = {Proceedings 2003 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS} 2003) ({Cat}. {No}.{03CH37453})},
	publisher = {IEEE},
	author = {Konolige, K. and Fox, D. and Limketkai, B. and Ko, J. and Stewart, B.},
	year = {2003},
	pages = {212--217},
	file = {Konolige et al. - 2003 - Map merging for distributed robot navigation.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\JBV5R22M\\Konolige et al. - 2003 - Map merging for distributed robot navigation.pdf:application/pdf},
}

@inproceedings{h_jacky_chang_multi-robot_2007,
	address = {San Diego, CA, USA},
	title = {Multi-robot {SLAM} with topological/metric maps},
	isbn = {978-1-4244-0911-2 978-1-4244-0912-9},
	url = {http://ieeexplore.ieee.org/document/4399142/},
	doi = {10.1109/IROS.2007.4399142},
	abstract = {In recent years, the success of single-robot SLAM has led to more multi-robot SLAM (MR-SLAM) research. A team of robots with MR-SLAM can explore an environment more efﬁciently and reliably; however, MR-SLAM also raises many challenging problems, including map fusion, unknown robot poses and scalability issues. The ﬁrst two problems can be considered as an optimization problem of ﬁnding a consistent joint map based on robots’ relative poses and sensory data. This optimization problem exhibits a similar property of a singlerobot topological/metric mapping. To exploit this property, we propose a multi-robot SLAM (MR-SLAM) algorithm, which builds a graph-like topological map with vertices representing local metric maps and edges describing relative positions of adjacent local maps. In this MR-SLAM algorithm, the map fusion between two robots can be naturally done by adding an edge that connects two topological maps, and the estimation of relative robot pose is simply performed by optimizing this edge. For the third scalable problem, the proposed algorithm is also scalable to the number of robots and the size of an environment. Computer simulations with a public data set and experimental work on Pioneer 3-DX robots have been conducted to validate the performance of the proposed MR-SLAM algorithm.},
	language = {en},
	urldate = {2021-12-20},
	booktitle = {2007 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	publisher = {IEEE},
	author = {{H. Jacky Chang} and {C. S. George Lee} and {Y. Charlie Hu} and {Yung-Hsiang Lu}},
	month = oct,
	year = {2007},
	pages = {1467--1472},
	annote = {Depends on meeting strategy between robots},
	file = {H. Jacky Chang et al. - 2007 - Multi-robot SLAM with topologicalmetric maps.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\PJWGUS7T\\H. Jacky Chang et al. - 2007 - Multi-robot SLAM with topologicalmetric maps.pdf:application/pdf},
}

@article{tomatis_hybrid_2003,
	title = {Hybrid simultaneous localization and map building: a natural integration of topological and metric},
	volume = {44},
	issn = {09218890},
	shorttitle = {Hybrid simultaneous localization and map building},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S092188900300006X},
	doi = {10.1016/S0921-8890(03)00006-X},
	abstract = {In this paper the metric and topological paradigms are integrated in a hybrid system for both localization and map building. A global topological map connects local metric maps, allowing a compact environment model, which does not require global metric consistency and permits both precision and robustness. Furthermore, the approach handles loops in the environment during automatic mapping by means of the information of the multimodal topological localization. The system uses a 360◦ laser scanner to extract corners and openings for the topological approach and lines for the metric method. This hybrid approach has been tested in a 50 m × 25 m portion of the institute building with the fully autonomous robot Donald Duck. Experiments are of four types: maps created by a complete exploration of the environment are compared to estimate their quality; test missions are randomly generated in order to evaluate the efﬁciency of the approach for both the localization and relocation; the fourth type of experiments shows the practicability of the approach for closing the loop.},
	language = {en},
	number = {1},
	urldate = {2021-12-20},
	journal = {Robotics and Autonomous Systems},
	author = {Tomatis, Nicola and Nourbakhsh, Illah and Siegwart, Roland},
	month = jul,
	year = {2003},
	pages = {3--14},
	file = {Tomatis et al. - 2003 - Hybrid simultaneous localization and map building.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\HF7R8QHB\\Tomatis et al. - 2003 - Hybrid simultaneous localization and map building.pdf:application/pdf},
}

@book{parker_distributed_2000,
	address = {Tokyo},
	title = {Distributed {Autonomous} {Robotic} {Systems} 4},
	isbn = {978-4-431-67991-2 978-4-431-67919-6},
	url = {http://link.springer.com/10.1007/978-4-431-67919-6},
	language = {en},
	urldate = {2021-12-20},
	publisher = {Springer Japan},
	editor = {Parker, Lynne E. and Bekey, George and Barhen, Jacob},
	year = {2000},
	doi = {10.1007/978-4-431-67919-6},
	file = {Parker et al. - 2000 - Distributed Autonomous Robotic Systems 4.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\YLI4D43C\\Parker et al. - 2000 - Distributed Autonomous Robotic Systems 4.pdf:application/pdf},
}

@inproceedings{renaudeau_hybrid_2018,
	address = {Brisbane, QLD},
	title = {Hybrid map mosaicing: {A} novel approach for large area mapping},
	isbn = {978-1-5386-5974-8},
	shorttitle = {Hybrid map mosaicing},
	url = {https://ieeexplore.ieee.org/document/8376266/},
	doi = {10.1109/SIMPAR.2018.8376266},
	abstract = {In this paper, we propose a new approach to global mapping of ground free spaces from aerial views in structured outdoor environments. The presented approach makes a topological mosaicing based on free space skeletonization and graph matching. The obtained environment model is a ground traversability map represented as a hybrid topological/metrical graph, which is a very suitable representation for ground navigation and planing. To validate this approach, the proposed algorithm is applied on aerial views provided by a UAV evolving over an experimental site and is compared with a recent stateof-the-art mosaicing solution.},
	language = {en},
	urldate = {2021-12-20},
	booktitle = {2018 {IEEE} {International} {Conference} on {Simulation}, {Modeling}, and {Programming} for {Autonomous} {Robots} ({SIMPAR})},
	publisher = {IEEE},
	author = {Renaudeau, Brice and Labbani-Igbida, Ouiddad and Mourioux, Gilles},
	month = may,
	year = {2018},
	pages = {23--28},
	file = {Renaudeau et al. - 2018 - Hybrid map mosaicing A novel approach for large a.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\J8EHDK9P\\Renaudeau et al. - 2018 - Hybrid map mosaicing A novel approach for large a.pdf:application/pdf},
}

@inproceedings{renaudeau_hybrid_2018-1,
	address = {Brisbane, QLD},
	title = {Hybrid map mosaicing: {A} novel approach for large area mapping},
	isbn = {978-1-5386-5974-8},
	shorttitle = {Hybrid map mosaicing},
	url = {https://ieeexplore.ieee.org/document/8376266/},
	doi = {10.1109/SIMPAR.2018.8376266},
	abstract = {In this paper, we propose a new approach to global mapping of ground free spaces from aerial views in structured outdoor environments. The presented approach makes a topological mosaicing based on free space skeletonization and graph matching. The obtained environment model is a ground traversability map represented as a hybrid topological/metrical graph, which is a very suitable representation for ground navigation and planing. To validate this approach, the proposed algorithm is applied on aerial views provided by a UAV evolving over an experimental site and is compared with a recent stateof-the-art mosaicing solution.},
	language = {en},
	urldate = {2021-12-20},
	booktitle = {2018 {IEEE} {International} {Conference} on {Simulation}, {Modeling}, and {Programming} for {Autonomous} {Robots} ({SIMPAR})},
	publisher = {IEEE},
	author = {Renaudeau, Brice and Labbani-Igbida, Ouiddad and Mourioux, Gilles},
	month = may,
	year = {2018},
	pages = {23--28},
	file = {Renaudeau et al. - 2018 - Hybrid map mosaicing A novel approach for large a.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\EQXFTX83\\Renaudeau et al. - 2018 - Hybrid map mosaicing A novel approach for large a.pdf:application/pdf},
}

@article{gorte_navigation_2019-1,
	title = {Navigation in {Indoor} {Voxel} {Models}},
	volume = {IV-2/W5},
	issn = {2194-9050},
	url = {https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/IV-2-W5/279/2019/},
	doi = {10.5194/isprs-annals-IV-2-W5-279-2019},
	abstract = {The paper proposes to use voxel models of building interiors to perform indoor navigation. The algorithms can be purely geometrical, not relying on semantic information about different building elements, such as floors, walls, stairways etc. Therefore, it is possible to use voxel models from different data sources, in addition to vector-to-raster conversions. The paper demonstrates this on the basis of tree different input types: hand measurements, point clouds and images of floorplans. On the basis of these models, the paper shows how to determine the navigable space in a voxel model for a pedestrian actor, and how to compute paths from arbitrary sources to specified destinations.},
	language = {en},
	urldate = {2021-12-22},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Gorte, B. and Zlatanova, S. and Fadli, F.},
	month = may,
	year = {2019},
	pages = {279--283},
	file = {10.1.1.29.9925.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\LP6FZGVB\\10.1.1.29.9925.pdf:application/pdf;Gorte et al. - 2019 - NAVIGATION IN INDOOR VOXEL MODELS.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\WVBU2HG9\\NAVIGATION_IN_INDOOR_VOXEL_MODELS.pdf:application/pdf;NAVIGATION_IN_INDOOR_VOXEL_MODELS.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\UX2U55I8\\NAVIGATION_IN_INDOOR_VOXEL_MODELS.pdf:application/pdf;NAVIGATION_IN_INDOOR_VOXEL_MODELS.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\6I8FSXQP\\NAVIGATION_IN_INDOOR_VOXEL_MODELS.pdf:application/pdf},
}

@article{yang_fast_2016,
	title = {A fast and robust local descriptor for {3D} point cloud registration},
	volume = {346-347},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025516300378},
	doi = {10.1016/j.ins.2016.01.095},
	abstract = {This paper proposes a novel local feature descriptor, called a local feature statistics histogram (LFSH), for efficient 3D point cloud registration. An LFSH forms a comprehensive description of local shape geometries by encoding their statistical properties on local depth, point density, and angles between normals. The sub-features in the LFSH descriptor are low-dimensional and quite efficient to compute. In addition, an optimized sample consensus (OSAC) algorithm is developed to iteratively estimate the optimum transformation from point correspondences. OSAC can handle the challenging cases of matching highly self-similar models. Based on the proposed LFSH and OSAC, a coarse-to-fine algorithm can be formed for 3D point cloud registration. Experiments and comparisons with the state-of-the-art descriptors demonstrate that LFSH is highly discriminative, robust, and significantly faster than other descriptors. Meanwhile, the proposed coarse-to-fine registration algorithm is demonstrated to be robust to common nuisances, including noise and varying point cloud resolutions, and can achieve high accuracy on both model data and scene data.},
	language = {en},
	urldate = {2022-01-18},
	journal = {Information Sciences},
	author = {Yang, Jiaqi and Cao, Zhiguo and Zhang, Qian},
	month = jun,
	year = {2016},
	keywords = {3D point cloud registration, Feature matching, Local feature descriptor, Point correspondences, Self-similar models},
	pages = {163--179},
	file = {ScienceDirect Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\WQ9GKWFG\\S0020025516300378.html:text/html},
}

@article{boyer_shrec_2011,
	title = {{SHREC} 2011: robust feature detection and description benchmark},
	shorttitle = {{SHREC} 2011},
	url = {http://arxiv.org/abs/1102.4258},
	abstract = {Feature-based approaches have recently become very popular in computer vision and image analysis applications, and are becoming a promising direction in shape retrieval. SHREC'11 robust feature detection and description benchmark simulates the feature detection and description stages of feature-based shape retrieval algorithms. The benchmark tests the performance of shape feature detectors and descriptors under a wide variety of transformations. The benchmark allows evaluating how algorithms cope with certain classes of transformations and strength of the transformations that can be dealt with. The present paper is a report of the SHREC'11 robust feature detection and description benchmark results.},
	urldate = {2022-01-18},
	journal = {arXiv:1102.4258 [cs]},
	author = {Boyer, E. and Bronstein, A. M. and Bronstein, M. M. and Bustos, B. and Darom, T. and Horaud, R. and Hotz, I. and Keller, Y. and Keustermans, J. and Kovnatsky, A. and Litman, R. and Reininghaus, J. and Sipiran, I. and Smeets, D. and Suetens, P. and Vandermeulen, D. and Zaharescu, A. and Zobel, V.},
	month = feb,
	year = {2011},
	note = {arXiv: 1102.4258},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: This is a full version of the SHREC'11 report published in 3DOR},
	file = {arXiv Fulltext PDF:C\:\\Users\\max.van.schendel\\Zotero\\storage\\WS79NDBR\\Boyer et al. - 2011 - SHREC 2011 robust feature detection and descripti.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\LDFM49R4\\1102.html:text/html},
}

@misc{qm13_azure_nodate,
	title = {Azure {Kinect} {DK} hardware specifications},
	url = {https://docs.microsoft.com/en-us/azure/kinect-dk/hardware-specification},
	abstract = {Understand the components, specifications, and capabilities of the Azure Kinect DK.},
	language = {en-us},
	urldate = {2022-01-17},
	author = {qm13},
	file = {Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\MBZNUG43\\hardware-specification.html:text/html},
}

@article{velasquez_hernandez_real-time_2020,
	title = {A real-time map merging strategy for robust collaborative reconstruction of unknown environments},
	volume = {145},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417419308267},
	doi = {10.1016/j.eswa.2019.113109},
	abstract = {The development of collaborative techniques for exploring and mapping environments has been rising in the last decade. These techniques, known as multi-robot SLAM (MRSLAM), aim to extend the use of autonomous mobile robots to autonomous multi-agent systems. The MRSLAM technique presented here consists mainly of a robust map merging algorithm and a decision-making algorithm that controls agents in the field. On the one hand, the proposed merging algorithm performs a consistent and robust map fusion in real time. It consists of an own corner detector, a cylindrical descriptor, a matching technique and the RANSAC algorithm. On the other hand, once the fusion of maps is performed, the decision-making algorithm is responsible for controlling the robot operation in the field, based on the general current state of the multi-robot system. The main contribution of this MRSLAM technique is the robust map merging algorithm, since it was implemented and validated in simulated and real scenarios, resulting in collaborative maps that are consistent with the environment and obtained in less than 280 ms. This technique also achieves a significant decrease in reconstruction time when two or three robots are used: up to 35\% in a simulated scenario and up to 49\% in a real one. The proposed MRSLAM technique shows important similarities to expert multi-agent systems, as it is able to control and organize a team of robots in order to collaboratively explore and map an unknown environment. This approach was developed under the ROS framework to be used and tested by the scientific and academic community.},
	language = {en},
	urldate = {2022-01-17},
	journal = {Expert Systems with Applications},
	author = {Velásquez Hernández, Carlos Alberto and Prieto Ortiz, Flavio Augusto},
	month = may,
	year = {2020},
	keywords = {Feature extraction, Collaborative reconstruction, Decision-making, Map merging, MRSLAM},
	pages = {113109},
	file = {ScienceDirect Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\5CJTRV3F\\S0957417419308267.html:text/html},
}

@article{dudek_topological_1998,
	title = {Topological {Exploration} {With} {Multiple} {Robots}},
	abstract = {This paper describes a technique whereby a group of mobile autonomous agents explores an unknown graph-like environment and constructs a topological map of it. The key idea is that the mobile agents start at a common node of the environment, explore independently (using a previously published algorithm) and agree to meet after a speci ed number of moves to exchange information in order to augment each other`s partial map of the world. Just after each exchange, robots have the same map of the world, which is a superset of each robot`s map just before the exchange. The process of harmonizing each other`s maps involves a combination of reasoning (for the areas that consist of paths common to all partial maps before the exchange) and physical movements of the robots, to check whether certain nodes in one map are identical to nodes in the rest of the maps.},
	language = {en},
	author = {Dudek, G and Jenkin, M and Milios, E and Wilkes, D},
	year = {1998},
	pages = {6},
	file = {Dudek et al. - TOPOLOGICAL EXPLORATION WITH MULTIPLE ROBOTS.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\T4S9FLBW\\Dudek et al. - TOPOLOGICAL EXPLORATION WITH MULTIPLE ROBOTS.pdf:application/pdf},
}

@article{kuipers_spatial_2000-1,
	title = {The {Spatial} {Semantic} {Hierarchy}},
	volume = {119},
	issn = {00043702},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0004370200000175},
	doi = {10.1016/S0004-3702(00)00017-5},
	abstract = {The Spatial Semantic Hierarchy is a model of knowledge of large-scale space consisting of multiple interacting representations, both qualitative and quantitative. The SSH is inspired by the properties of the human cognitive map, and is intended to serve both as a model of the human cognitive map and as a method for robot exploration and map-building. The multiple levels of the SSH express states of partial knowledge, and thus enable the human or robotic agent to deal robustly with uncertainty during both learning and problem-solving.},
	language = {en},
	number = {1-2},
	urldate = {2022-01-10},
	journal = {Artificial Intelligence},
	author = {Kuipers, Benjamin},
	month = may,
	year = {2000},
	pages = {191--233},
	file = {Kuipers - 2000 - The Spatial Semantic Hierarchy.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\FR87EKM3\\Kuipers - 2000 - The Spatial Semantic Hierarchy.pdf:application/pdf},
}

@article{kuipers_modeling_1978,
	title = {Modeling spatial knowledge},
	volume = {2},
	issn = {0364-0213},
	url = {https://www.sciencedirect.com/science/article/pii/S0364021378800032},
	doi = {10.1016/S0364-0213(78)80003-2},
	abstract = {A person's cognitive map, or knowledge of large-scale space, is built up from observations gathered as he travels through the environment. It acts as a problem solver to find routes and relative positions, as well as describing the current location. The TOUR model captures the multiple representations that make up the cognitive map, the problem-solving strategies it uses, and the mechanisms for assimilating new information. The representations have rich collections of states of partial knowledge, which support many of the performance characteristics of common-sense knowledge.},
	language = {en},
	number = {2},
	urldate = {2022-01-10},
	journal = {Cognitive Science},
	author = {Kuipers, Benjamin},
	month = apr,
	year = {1978},
	pages = {129--153},
	file = {Full Text:C\:\\Users\\max.van.schendel\\Zotero\\storage\\CLCKY9RP\\Kuipers - 1978 - Modeling spatial knowledge.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\UZZ7R89I\\S0364021378800032.html:text/html},
}

@article{kuipers_robust_1988,
	title = {A {Robust}, {Qualitative} {Method} for {Robot} {Spatial} {Learning}},
	abstract = {We present a qualitative method for a mobile robot to explore an unknown environment and learn a map, which can be robust in the face of various possible errors in the real world. Procedural knowledge for the movement, topological model for the structure of the environment, and metrical information for geometrical accuracy are separately represented in our method, whereas traditional methods describe the environment mainly by metrical information. The topological model consists of distinctive places and local travel edges linking nearby distinctive places. A distinctive place is defined as the local maximum of some measure of distinctiveness appropriate to its immediate neighborhood, and is found by a hill-climbing search. Local travel edges are defined in terms of local control strategies required for wavel. How to find distinctive places and follow edges is the procedural knowledge which the robot learns dynamically during exploration stage and guides the robot in the navigation stage. An accurate topological model is created by linking places and edges; and allows metrical information to be ac- cumulated with reduced vulnerability to metrical errors. We describe a working simulation in which a robot, NX, with range sensors explores a variety of 2-D environments and we give its successful results under varying levels of random sensor error.},
	author = {Kuipers, Benjamin and Byun, Yung-Tai},
	year = {1988},
	file = {Full Text PDF:C\:\\Users\\max.van.schendel\\Zotero\\storage\\MYU2A7WC\\Kuipers and Byun - 2003 - A Robust, Qualitative Method for Robot Spatial Lea.pdf:application/pdf},
}

@misc{noauthor_robust_nodate,
	title = {A {Robust}, {Qualitative} {Method} for {Robot} {Spatial} {Learning}},
	url = {https://aaai.org/Library/AAAI/1988/aaai88-137.php},
	urldate = {2022-01-10},
}

@article{kuipers_robot_1991,
	series = {Special {Issue} {Toward} {Learning} {Robots}},
	title = {A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations},
	volume = {8},
	issn = {0921-8890},
	url = {https://www.sciencedirect.com/science/article/pii/092188909190014C},
	doi = {10.1016/0921-8890(91)90014-C},
	abstract = {Kuipers, B. and Byun, Y.T., A robot exploration and mapping strategy based on a sematic hierarchy of spatial representations, Robotics and Autonomous System, 8 (1991) 47–63. We have developed a robust qualitative method for robot exploration, mapping, and navigation in large-scale spatial environments. Experiments with a simulated robot in a variety of complex 2D environments have demonstrated that our qualitative method can build an accurate map of a previously unkown environment in spite of substantial random and systematic sensorimotor error. Most current approaches to robot exploration and mapping analyze sensor input to build a geometrically precise map of the environment, then extract topological structure from the geometric description. Our approach recognizes and exploits qualitative properties of large-scale before relatively error-prone geometrical properties. [sensorimotor ↔ control] → topology → geometry At the control level, distinctive places and distinctive travel edges are identified based on the interaction between the robot's control strategies, its sensorimotor system, and the world. A distinctive place is defined as the local maximum of a distinctiveness measure appropriate to its immediate neighborhood, and is found by a hill-climbing control strategy. A distinctive travel edge, similarly, is defined by a suitable measure and a path-following control strategy. The topological network description is created by linking the distinctive places and travel edges.Metrical information is then incrementally assimilated into localgeometric descriptions of places and edges, and finally merged into a global geometric map. Topological ambiguity arising from sensorily indistinguishable places can be resolved at the topological level by the exploration strategy. With this representation, successful navigation is not critically dependent on the accuracy, or even the existence, of the geometrical description. We present examples demonstrating the process by which the robot explores and builds a map of a complex environment, including the effect of sensory errors. We also discuss new research directions that are suggested by this approach.},
	language = {en},
	number = {1},
	urldate = {2022-01-10},
	journal = {Robotics and Autonomous Systems},
	author = {Kuipers, Benjamin and Byun, Yung-Tai},
	month = nov,
	year = {1991},
	keywords = {Cognitive map, Robot exploration, Spatial reasoning, Distinctive place, Environmental mapping, Large-scale space, Topological map},
	pages = {47--63},
	file = {ScienceDirect Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\LVFBB7QQ\\092188909190014C.html:text/html},
}

@article{thrun_learning_1998,
	title = {Learning metric-topological maps for indoor mobile robot navigation},
	volume = {99},
	issn = {0004-3702},
	url = {https://www.sciencedirect.com/science/article/pii/S0004370297000787},
	doi = {10.1016/S0004-3702(97)00078-7},
	abstract = {Autonomous robots must be able to learn and maintain models of their environments. Research on mobile robot navigation has produced two major paradigms for mapping indoor environments: grid-based and topological. While grid-based methods produce accurate metric maps, their complexity often prohibits efficient planning and problem solving in large-scale indoor environments. Topological maps, on the other hand, can be used much more efficiently, yet accurate and consistent topological maps are often difficult to learn and maintain in large-scale environments, particularly if momentary sensor data is highly ambiguous. This paper describes an approach that integrates both paradigms: grid-based and topological. Grid-based maps are learned using artificial neural networks and naive Bayesian integration. Topological maps are generated on top of the grid-based maps, by partitioning the latter into coherent regions. By combining both paradigms, the approach presented here gains advantages from both worlds: accuracy/consistency and efficiency. The paper gives results for autonomous exploration, mapping and operation of a mobile robot in populated multi-room environments.},
	language = {en},
	number = {1},
	urldate = {2022-01-10},
	journal = {Artificial Intelligence},
	author = {Thrun, Sebastian},
	month = feb,
	year = {1998},
	keywords = {Autonomous robots, Exploration, Mobile robots, Neural networks, Occupancy grids, Path planning, Planning, Robot mapping, Topological maps},
	pages = {21--71},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\max.van.schendel\\Zotero\\storage\\KN6ND6II\\Thrun - 1998 - Learning metric-topological maps for indoor mobile.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\XJMSG5IF\\S0004370297000787.html:text/html},
}

@article{yeap_towards_1988,
	title = {Towards a computational theory of cognitive maps},
	volume = {34},
	issn = {0004-3702},
	url = {https://www.sciencedirect.com/science/article/pii/0004370288900641},
	doi = {10.1016/0004-3702(88)90064-1},
	abstract = {A computational theory of cognitive maps is developed which can explain some of the current findings about cognitive maps in the psychological literature and which provides a coherent framework for future development. The theory is tested with several computer implementations which demonstrate how the shape of the environment is computed and how one's conceptual representation of the environment is derived. We begin with the idea that the cognitive mapping process should be studied as two loosely coupled modules: The first module, known as the raw cognitive map, is computed from information made explicit in Marr's 212-D sketch and not from high-level descriptions of what we perceive. The second module, known as the full cognitive map, takes the raw cognitive map as input and produces different “abstract representations” for solving high-level spatial tasks faced by the individual.},
	language = {en},
	number = {3},
	urldate = {2022-01-09},
	journal = {Artificial Intelligence},
	author = {Yeap, Wai K.},
	month = apr,
	year = {1988},
	pages = {297--360},
	file = {ScienceDirect Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\6R7CBD3Z\\0004370288900641.html:text/html;Yeap - 1988 - Towards a computational theory of cognitive maps.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\TUEB6FFV\\Yeap - 1988 - Towards a computational theory of cognitive maps.pdf:application/pdf},
}

@inproceedings{rusinkiewicz_efficient_2001,
	title = {Efficient variants of the {ICP} algorithm},
	doi = {10.1109/IM.2001.924423},
	abstract = {The ICP (Iterative Closest Point) algorithm is widely used for geometric alignment of three-dimensional models when an initial estimate of the relative pose is known. Many variants of ICP have been proposed, affecting all phases of the algorithm from the selection and matching of points to the minimization strategy. We enumerate and classify many of these variants, and evaluate their effect on the speed with which the correct alignment is reached. In order to improve convergence for nearly-flat meshes with small features, such as inscribed surfaces, we introduce a new variant based on uniform sampling of the space of normals. We conclude by proposing a combination of ICP variants optimized for high speed. We demonstrate an implementation that is able to align two range images in a few tens of milliseconds, assuming a good initial guess. This capability has potential application to real-time 3D model acquisition and model-based tracking.},
	booktitle = {Proceedings {Third} {International} {Conference} on 3-{D} {Digital} {Imaging} and {Modeling}},
	author = {Rusinkiewicz, S. and Levoy, M.},
	month = may,
	year = {2001},
	keywords = {Layout, Solid modeling, Convergence, Geometry, Image sampling, Iterative algorithms, Iterative closest point algorithm, Iterative methods, Minimization methods, Rough surfaces},
	pages = {145--152},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\max.van.schendel\\Zotero\\storage\\NW9EF7KA\\924423.html:text/html},
}

@inproceedings{gelfand_geometrically_2003,
	title = {Geometrically stable sampling for the {ICP} algorithm},
	doi = {10.1109/IM.2003.1240258},
	abstract = {The iterative closest point (ICP) algorithm is a widely used method for aligning three-dimensional point sets. The quality of alignment obtained by this algorithm depends heavily on choosing good pairs of corresponding points in the two datasets. If too many points are chosen from featureless regions of the data, the algorithm converges slowly, finds the wrong pose, or even diverges, especially in the presence of noise or miscalibration in the input data. We describe a method for detecting uncertainty in pose, and we propose a point selection strategy for ICP that minimizes this uncertainty by choosing samples that constrain potentially unstable transformations.},
	booktitle = {Fourth {International} {Conference} on 3-{D} {Digital} {Imaging} and {Modeling}, 2003. {3DIM} 2003. {Proceedings}.},
	author = {Gelfand, N. and Ikemoto, L. and Rusinkiewicz, S. and Levoy, M.},
	month = oct,
	year = {2003},
	keywords = {Convergence, Geometry, Iterative algorithms, Iterative closest point algorithm, Iterative methods, Error correction, Frequency, Sampling methods, Stability, Uncertainty},
	pages = {260--267},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\max.van.schendel\\Zotero\\storage\\DWLJFSBC\\1240258.html:text/html;Submitted Version:C\:\\Users\\max.van.schendel\\Zotero\\storage\\97W4BLVW\\Gelfand et al. - 2003 - Geometrically stable sampling for the ICP algorith.pdf:application/pdf},
}

@inproceedings{serafin_nicp_2015,
	title = {{NICP}: {Dense} normal based point cloud registration},
	shorttitle = {{NICP}},
	doi = {10.1109/IROS.2015.7353455},
	abstract = {In this paper we present a novel on-line method to recursively align point clouds. By considering each point together with the local features of the surface (normal and curvature), our method takes advantage of the 3D structure around the points for the determination of the data association between two clouds. The algorithm relies on a least squares formulation of the alignment problem, that minimizes an error metric depending on these surface characteristics. We named the approach Normal Iterative Closest Point (NICP in short). Extensive experiments on publicly available benchmark data show that NICP outperforms other state-of-the-art approaches.},
	booktitle = {2015 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Serafin, Jacopo and Grisetti, Giorgio},
	month = sep,
	year = {2015},
	keywords = {Measurement, Iterative closest point algorithm, Cameras, Robustness, Sensors, Three-dimensional displays, Transforms},
	pages = {742--749},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\max.van.schendel\\Zotero\\storage\\RFVXYENH\\7353455.html:text/html;Submitted Version:C\:\\Users\\max.van.schendel\\Zotero\\storage\\3VQSYHGI\\Serafin and Grisetti - 2015 - NICP Dense normal based point cloud registration.pdf:application/pdf},
}

@article{mura_automatic_2014,
	title = {Automatic room detection and reconstruction in cluttered indoor environments with complex room layouts},
	volume = {44},
	issn = {00978493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0097849314000661},
	doi = {10.1016/j.cag.2014.07.005},
	abstract = {We present a robust approach for reconstructing the main architectural structure of complex indoor environments given a set of cluttered 3D input range scans. Our method uses an efﬁcient occlusionaware process to extract planar patches as candidate walls, separating them from clutter and coping with missing data, and automatically extracts the individual rooms that compose the environment by applying a diffusion process on the space partitioning induced by the candidate walls. This diffusion process, which has a natural interpretation in terms of heat propagation, makes our method robust to artifacts and other imperfections that occur in typical scanned data of interiors. For each room, our algorithm reconstructs an accurate polyhedral model by applying methods from robust statistics. We demonstrate the validity of our approach by evaluating it on both synthetic models and real-world 3D scans of indoor environments.},
	language = {en},
	urldate = {2022-02-17},
	journal = {Computers \& Graphics},
	author = {Mura, Claudio and Mattausch, Oliver and Jaspe Villanueva, Alberto and Gobbetti, Enrico and Pajarola, Renato},
	month = nov,
	year = {2014},
	pages = {20--32},
	file = {Mura et al. - 2014 - Automatic room detection and reconstruction in clu.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\JQRLXPZE\\Mura et al. - 2014 - Automatic room detection and reconstruction in clu.pdf:application/pdf},
}

@article{ochmann_automatic_2019,
	title = {Automatic reconstruction of fully volumetric {3D} building models from oriented point clouds},
	volume = {151},
	issn = {09242716},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0924271619300863},
	doi = {10.1016/j.isprsjprs.2019.03.017},
	abstract = {We present a novel method for reconstructing parametric, volumetric, multi-story building models from unstructured, unfiltered indoor point clouds with oriented normals by means of solving an integer linear optimization problem. Our approach overcomes limitations of previous methods in several ways: First, we drop assumptions about the input data such as the availability of separate scans as an initial room segmentation. Instead, a fully automatic room segmentation and outlier removal is performed on the unstructured point clouds. Second, restricting the solution space of our optimization approach to arrangements of volumetric wall entities representing the structure of a building enforces a consistent model of volumetric, interconnected walls fitted to the observed data instead of unconnected, paper-thin surfaces. Third, we formulate the optimization as an integer linear programming problem which allows for an exact solution instead of the approximations achieved with most previous techniques. Lastly, our optimization approach is designed to incorporate hard constraints which were difficult or even impossible to integrate before. We evaluate and demonstrate the capabilities of our proposed approach on a variety of complex real-world point clouds.},
	language = {en},
	urldate = {2022-02-16},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Ochmann, Sebastian and Vock, Richard and Klein, Reinhard},
	month = may,
	year = {2019},
	pages = {251--262},
	file = {Ochmann et al. - 2019 - Automatic reconstruction of fully volumetric 3D bu.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\SSHCY7GD\\Ochmann et al. - 2019 - Automatic reconstruction of fully volumetric 3D bu.pdf:application/pdf},
}

@article{pintore_state---art_2020,
	title = {State-of-the-art in {Automatic} {3D} {Reconstruction} of {Structured} {Indoor} {Environments}},
	volume = {39},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14021},
	doi = {10.1111/cgf.14021},
	abstract = {Creating high-level structured 3D models of real-world indoor scenes from captured data is a fundamental task which has important applications in many fields. Given the complexity and variability of interior environments and the need to cope with noisy and partial captured data, many open research problems remain, despite the substantial progress made in the past decade. In this survey, we provide an up-to-date integrative view of the field, bridging complementary views coming from computer graphics and computer vision. After providing a characterization of input sources, we define the structure of output models and the priors exploited to bridge the gap between imperfect sources and desired output. We then identify and discuss the main components of a structured reconstruction pipeline, and review how they are combined in scalable solutions working at the building level. We finally point out relevant research issues and analyze research trends.},
	language = {en},
	number = {2},
	urldate = {2022-02-16},
	journal = {Computer Graphics Forum},
	author = {Pintore, Giovanni and Mura, Claudio and Ganovelli, Fabio and Fuentes-Perez, Lizeth and Pajarola, Renato and Gobbetti, Enrico},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14021},
	keywords = {• Applied computing → Computer-aided design, • Computing methodologies → Computer graphics, CCS Concepts, Computer vision, Computer vision problems, Reconstruction, Shape inference, Shape modeling},
	pages = {667--699},
	file = {Full Text PDF:C\:\\Users\\max.van.schendel\\Zotero\\storage\\XVB3XLTF\\Pintore et al. - 2020 - State-of-the-art in Automatic 3D Reconstruction of.pdf:application/pdf;Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\7BGAXIQR\\cgf.html:text/html},
}

@inproceedings{bobkov_room_2017,
	address = {Hong Kong, Hong Kong},
	title = {Room segmentation in {3D} point clouds using anisotropic potential fields},
	isbn = {978-1-5090-6067-2},
	url = {http://ieeexplore.ieee.org/document/8019484/},
	doi = {10.1109/ICME.2017.8019484},
	abstract = {Automatic and robust partitioning of indoor 3D point clouds into rooms is a central requirement for emerging applications such as indoor navigation or facility management. Existing works are either based on the Manhattan-world assumption or rely on the availability of the scanner pose information. Instead, we follow the architectural deﬁnition of a room and consider it as an inner free space separated from other spaces through openings or partitions. For this we formulate an anisotropic potential ﬁeld for 3D environments and illustrate how it can be used for room segmentation in the proposed segmentation pipeline. The experimental results conﬁrm that our method outperforms state-of-the-art methods on a number of datasets including those that violate the Manhattan-world assumption.},
	language = {en},
	urldate = {2022-02-16},
	booktitle = {2017 {IEEE} {International} {Conference} on {Multimedia} and {Expo} ({ICME})},
	publisher = {IEEE},
	author = {Bobkov, Dmytro and Kiechle, Martin and Hilsenbeck, Sebastian and Steinbach, Eckehard},
	month = jul,
	year = {2017},
	pages = {727--732},
	file = {Bobkov et al. - 2017 - Room segmentation in 3D point clouds using anisotr.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\L9IAZGJE\\Bobkov et al. - 2017 - Room segmentation in 3D point clouds using anisotr.pdf:application/pdf},
}

@article{zheng_learning_nodate,
	title = {Learning {Graph}-{Structured} {Sum}-{Product} {Networks} for {Probabilistic} {Semantic} {Maps}},
	abstract = {We introduce Graph-Structured Sum-Product Networks (GraphSPNs), a probabilistic approach to structured prediction for problems where dependencies between latent variables are expressed in terms of arbitrary, dynamic graphs. While many approaches to structured prediction place strict constraints on the interactions between inferred variables, many real-world problems can be only characterized using complex graph structures of varying size, often contaminated with noise when obtained from real data. Here, we focus on one such problem in the domain of robotics. We demonstrate how GraphSPNs can be used to bolster inference about semantic, conceptual place descriptions using noisy topological relations discovered by a robot exploring large-scale ofﬁce spaces. Through experiments, we show that GraphSPNs consistently outperform the traditional approach based on undirected graphical models, successfully disambiguating information in global semantic maps built from uncertain, noisy local evidence. We further exploit the probabilistic nature of the model to infer marginal distributions over semantic descriptions of as yet unexplored places and detect spatial environment conﬁgurations that are novel and incongruent with the known evidence.},
	language = {en},
	author = {Zheng, Kaiyu and Pronobis, Andrzej and Rao, Rajesh P N},
	pages = {9},
	file = {Zheng et al. - Learning Graph-Structured Sum-Product Networks for.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\RETBXHB4\\Zheng et al. - Learning Graph-Structured Sum-Product Networks for.pdf:application/pdf},
}

@article{friedman_voronoi_2007,
	title = {Voronoi {Random} {Fields}: {Extracting} the {Topological} {Structure} of {Indoor} {Environments} via {Place} {Labeling}},
	abstract = {The ability to build maps of indoor environments is extremely important for autonomous mobile robots. In this paper we introduce Voronoi random ﬁelds (VRFs), a novel technique for mapping the topological structure of indoor environments. Our maps describe environments in terms of their spatial layout along with information about the different places and their connectivity. To build these maps, we extract a Voronoi graph from an occupancy grid map generated with a laser range-ﬁnder, and then represent each point on the Voronoi graph as a node of a conditional random ﬁeld, which is a discriminatively trained graphical model. The resulting VRF estimates the label of each node, integrating features from both the map and the Voronoi topology. The labels provide a segmentation of an environment, with the different segments corresponding to rooms, hallways, or doorways. Experiments using different maps show that our technique is able to label unknown environments based on parameters learned from other environments.},
	language = {en},
	author = {Friedman, Stephen and Pasula, Hanna and Fox, Dieter},
	year = {2007},
	pages = {6},
	file = {Friedman et al. - Voronoi Random Fields Extracting the Topological .pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\QJ9YLS9M\\Friedman et al. - Voronoi Random Fields Extracting the Topological .pdf:application/pdf},
}

@article{rosinol_3d_2020,
	title = {{3D} {Dynamic} {Scene} {Graphs}: {Actionable} {Spatial} {Perception} with {Places}, {Objects}, and {Humans}},
	shorttitle = {{3D} {Dynamic} {Scene} {Graphs}},
	url = {http://arxiv.org/abs/2002.06289},
	abstract = {We present a uniﬁed representation for actionable spatial perception: 3D Dynamic Scene Graphs. Scene graphs are directed graphs where nodes represent entities in the scene (e.g., objects, walls, rooms), and edges represent relations (e.g., inclusion, adjacency) among nodes. Dynamic scene graphs (DSGs) extend this notion to represent dynamic scenes with moving agents (e.g., humans, robots), and to include actionable information that supports planning and decision-making (e.g., spatiotemporal relations, topology at different levels of abstraction). Our second contribution is to provide the ﬁrst fully automatic Spatial PerceptIon eNgine (SPIN) to build a DSG from visualinertial data. We integrate state-of-the-art techniques for object and human detection and pose estimation, and we describe how to robustly infer object, robot, and human nodes in crowded scenes.},
	language = {en},
	urldate = {2022-02-09},
	journal = {arXiv:2002.06289 [cs]},
	author = {Rosinol, Antoni and Gupta, Arjun and Abate, Marcus and Shi, Jingnan and Carlone, Luca},
	month = jun,
	year = {2020},
	note = {arXiv: 2002.06289},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics, Computer Science - Artificial Intelligence},
	annote = {Comment: 11 pages, 5 figures},
	file = {Rosinol et al. - 2020 - 3D Dynamic Scene Graphs Actionable Spatial Percep.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\YR2RXTQ6\\Rosinol et al. - 2020 - 3D Dynamic Scene Graphs Actionable Spatial Percep.pdf:application/pdf},
}

@article{hughes_hydra_2022,
	title = {Hydra: {A} {Real}-time {Spatial} {Perception} {Engine} for {3D} {Scene} {Graph} {Construction} and {Optimization}},
	shorttitle = {Hydra},
	url = {http://arxiv.org/abs/2201.13360},
	abstract = {3D scene graphs have recently emerged as a powerful high-level representation of 3D environments. A 3D scene graph describes the environment as a layered graph where nodes represent spatial concepts at multiple levels of abstraction and edges represent relations between concepts. While 3D scene graphs can serve as an advanced "mental model" for robots, how to build such a rich representation in real-time is still uncharted territory. This paper describes the first real-time Spatial Perception engINe (SPIN), a suite of algorithms to build a 3D scene graph from sensor data in real-time. Our first contribution is to develop real-time algorithms to incrementally construct the layers of a scene graph as the robot explores the environment; these algorithms build a local Euclidean Signed Distance Function (ESDF) around the current robot location, extract a topological map of places from the ESDF, and then segment the places into rooms using an approach inspired by community-detection techniques. Our second contribution is to investigate loop closure detection and optimization in 3D scene graphs. We show that 3D scene graphs allow defining hierarchical descriptors for loop closure detection; our descriptors capture statistics across layers in the scene graph, ranging from low-level visual appearance, to summary statistics about objects and places. We then propose the first algorithm to optimize a 3D scene graph in response to loop closures; our approach relies on embedded deformation graphs to simultaneously correct all layers of the scene graph. We implement the proposed SPIN into a highly parallelized architecture, named Hydra, that combines fast early and mid-level perception processes with slower high-level perception. We evaluate Hydra on simulated and real data and show it is able to reconstruct 3D scene graphs with an accuracy comparable with batch offline methods, while running online.},
	language = {en},
	urldate = {2022-02-09},
	journal = {arXiv:2201.13360 [cs]},
	author = {Hughes, Nathan and Chang, Yun and Carlone, Luca},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.13360},
	keywords = {Computer Science - Robotics},
	annote = {Comment: 11 pages, 10 figures},
	file = {Hughes et al. - 2022 - Hydra A Real-time Spatial Perception Engine for 3.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\JB97JKE8\\Hughes et al. - 2022 - Hydra A Real-time Spatial Perception Engine for 3.pdf:application/pdf},
}

@article{bobkov_semantic_nodate,
	title = {Semantic {Understanding} of {3D} {Point} {Clouds} of {Indoor} {Environments}},
	language = {de},
	author = {Bobkov, Dmytro D},
	pages = {154},
	file = {Bobkov - Semantic Understanding of 3D Point Clouds of Indoo.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\7CAEVUF4\\Bobkov - Semantic Understanding of 3D Point Clouds of Indoo.pdf:application/pdf},
}

@inproceedings{bormann_room_2016,
	address = {Stockholm, Sweden},
	title = {Room segmentation: {Survey}, implementation, and analysis},
	isbn = {978-1-4673-8026-3},
	shorttitle = {Room segmentation},
	url = {https://ieeexplore.ieee.org/document/7487234/},
	doi = {10.1109/ICRA.2016.7487234},
	abstract = {The division of ﬂoor plans or navigation maps into single rooms or similarly meaningful semantic units is central to numerous tasks in robotics such as topological mapping, semantic mapping, place categorization, human-robotinteraction, or automatized professional cleaning. Although many map partitioning algorithms have been proposed for various applications there is a lack of comparative studies on these different algorithms. This paper surveys the literature on room segmentation and provides four publicly available implementations of popular methods, which target the semantic mapping domain and are tuned to yield segmentations into complete rooms. In an attempt to provide new users of such technologies guidance in the choice of map segmentation algorithm, those methods are compared qualitatively and quantitatively using several criteria. The evaluation is based on a novel compilation of 20 challenging ﬂoor plans.},
	language = {en},
	urldate = {2022-02-08},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Bormann, Richard and Jordan, Florian and Li, Wenzhe and Hampp, Joshua and Hagele, Martin},
	month = may,
	year = {2016},
	pages = {1019--1026},
	file = {Bormann et al. - 2016 - Room segmentation Survey, implementation, and ana.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\KZPXRH3J\\Bormann et al. - 2016 - Room segmentation Survey, implementation, and ana.pdf:application/pdf},
}

@article{tao_fast_2020,
	title = {Fast and {Automatic} {Registration} of {Terrestrial} {Point} {Clouds} {Using} {2D} {Line} {Features}},
	volume = {12},
	doi = {10.3390/rs12081283},
	abstract = {Point cloud registration, as the first step for the use of point cloud data, has attracted increasing attention. In order to obtain the entire point cloud of a scene, the registration of point clouds from multiple views is necessary. In this paper, we propose an automatic method for the coarse registration of point clouds. The 2D lines are first extracted from the two point clouds being matched. Then, the line correspondences are established and the 2D transformation is calculated. Finally, a method is developed to calculate the displacement along the z-axis. With the 2D transformation and displacement, the 3D transformation can be easily achieved. Thus, the two point clouds are aligned together. The experimental results well demonstrate that our method can obtain high-precision registration results and is computationally very efficient. In the experimental results obtained by our method, the biggest rotation error is 0.5219o, and the biggest horizontal and vertical errors are 0.2319 m and 0.0119 m, respectively. The largest total computation time is only 713.4647 s.},
	journal = {Remote Sensing},
	author = {Tao, Wuyong and Hua, Xianghong and Zhiping, Chen and Tian, Pengju},
	month = apr,
	year = {2020},
	pages = {128},
	annote = {Only used for figure in presentation of rough and fine registration},
	file = {Full Text:C\:\\Users\\max.van.schendel\\Zotero\\storage\\5EE6U9P6\\Tao et al. - 2020 - Fast and Automatic Registration of Terrestrial Poi.pdf:application/pdf},
}

@misc{noauthor_figure_nodate,
	title = {Figure 4. {The} coarse registration result of {Apartment}. (a) {The} source...},
	url = {https://www.researchgate.net/figure/The-coarse-registration-result-of-Apartment-a-The-source-and-target-point-clouds-b_fig2_340771096},
	abstract = {Download scientific diagram {\textbar} The coarse registration result of Apartment. (a) The source and target point clouds. (b) The registration result of the simplified 2D point clouds. (c) The registration result of the 3D point clouds. (d) The registered point clouds after removing the points on the ceiling for a better view. from publication: Fast and Automatic Registration of Terrestrial Point Clouds Using 2D Line Features {\textbar} Point cloud registration, as the first step for the use of point cloud data, has attracted increasing attention. In order to obtain the entire point cloud of a scene, the registration of point clouds from multiple views is necessary. In this paper, we propose an automatic... {\textbar} Point Clouds, Automatism and 3D {\textbar} ResearchGate, the professional network for scientists.},
	language = {en},
	urldate = {2022-01-27},
	journal = {ResearchGate},
	file = {Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\HNZAIQUB\\The-coarse-registration-result-of-Apartment-a-The-source-and-target-point-clouds-b_fig2_3407710.html:text/html},
}

@article{frias_point_2020,
	title = {{POINT} {CLOUD} {ROOM} {SEGMENTATION} {BASED} {ON} {INDOOR} {SPACES} {AND} {3D} {MATHEMATICAL} {MORPHOLOGY}},
	volume = {XLIV-4/W1-2020},
	issn = {2194-9034},
	url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIV-4-W1-2020/49/2020/},
	doi = {10.5194/isprs-archives-XLIV-4-W1-2020-49-2020},
	abstract = {Room segmentation is a matter of ongoing interesting for indoor navigation and reconstruction in robotics and AEC. While in robotics field, the problem room segmentation has been typically addressed on 2D floorplan, interest in enrichment 3D models providing more detailed representation of indoors has been growing in the AEC. Point clouds make available more realistic and update but room segmentation from point clouds is still a challenging topic. This work presents a method to carried out point cloud segmentation into rooms based on 3D mathematical morphological operations. First, the input point cloud is voxelized and indoor empty voxels are extracted by CropHull algorithm. Then, a morphological erosion is performed on the 3D image of indoor empty voxels in order to break connectivity between voxels belonging to adjacent rooms. Remaining voxels after erosion are clustered by a 3D connected components algorithm so that each room is individualized. Room morphology is retrieved by individual 3D morphological dilation on clustered voxels. Finally, unlabelled occupied voxels are classified according proximity to labelled empty voxels after dilation operation. The method was tested in two real cases and segmentation performance was evaluated with encouraging results.},
	language = {en},
	urldate = {2022-01-27},
	journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Frías, E. and Balado, J. and Díaz-Vilariño, L. and Lorenzo, H.},
	month = sep,
	year = {2020},
	pages = {49--55},
	file = {Frías et al. - 2020 - POINT CLOUD ROOM SEGMENTATION BASED ON INDOOR SPAC.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\HL7TNZDN\\Frías et al. - 2020 - POINT CLOUD ROOM SEGMENTATION BASED ON INDOOR SPAC.pdf:application/pdf},
}

@article{poux_voxel-based_2019,
	title = {Voxel-based {3D} {Point} {Cloud} {Semantic} {Segmentation}: {Unsupervised} {Geometric} and {Relationship} {Featuring} vs {Deep} {Learning} {Methods}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2220-9964},
	shorttitle = {Voxel-based {3D} {Point} {Cloud} {Semantic} {Segmentation}},
	url = {https://www.mdpi.com/2220-9964/8/5/213},
	doi = {10.3390/ijgi8050213},
	abstract = {Automation in point cloud data processing is central in knowledge discovery within decision-making systems. The definition of relevant features is often key for segmentation and classification, with automated workflows presenting the main challenges. In this paper, we propose a voxel-based feature engineering that better characterize point clusters and provide strong support to supervised or unsupervised classification. We provide different feature generalization levels to permit interoperable frameworks. First, we recommend a shape-based feature set (SF1) that only leverages the raw X, Y, Z attributes of any point cloud. Afterwards, we derive relationship and topology between voxel entities to obtain a three-dimensional (3D) structural connectivity feature set (SF2). Finally, we provide a knowledge-based decision tree to permit infrastructure-related classification. We study SF1/SF2 synergy on a new semantic segmentation framework for the constitution of a higher semantic representation of point clouds in relevant clusters. Finally, we benchmark the approach against novel and best-performing deep-learning methods while using the full S3DIS dataset. We highlight good performances, easy-integration, and high F1-score ({\textgreater} 85\%) for planar-dominant classes that are comparable to state-of-the-art deep learning.},
	language = {en},
	number = {5},
	urldate = {2022-01-27},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Poux, Florent and Billen, Roland},
	month = may,
	year = {2019},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {3D point cloud, 3D semantics, classification, deep learning, feature extraction, semantic segmentation, voxel},
	pages = {213},
	file = {Full Text PDF:C\:\\Users\\max.van.schendel\\Zotero\\storage\\WW26S4RN\\Poux and Billen - 2019 - Voxel-based 3D Point Cloud Semantic Segmentation .pdf:application/pdf;Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\8UW3IMDG\\htm.html:text/html},
}

@inproceedings{gojcic_perfect_2019,
	address = {Long Beach, CA, USA},
	title = {The {Perfect} {Match}: {3D} {Point} {Cloud} {Matching} {With} {Smoothed} {Densities}},
	isbn = {978-1-72813-293-8},
	shorttitle = {The {Perfect} {Match}},
	url = {https://ieeexplore.ieee.org/document/8954296/},
	doi = {10.1109/CVPR.2019.00569},
	abstract = {We propose 3DSmoothNet, a full workﬂow to match 3D point clouds with a siamese deep learning architecture and fully convolutional layers using a voxelized smoothed density value (SDV) representation. The latter is computed per interest point and aligned to the local reference frame (LRF) to achieve rotation invariance. Our compact, learned, rotation invariant 3D point cloud descriptor achieves 94.9\% average recall on the 3DMatch benchmark data set [49], outperforming the state-of-the-art by more than 20 percent points with only 32 output dimensions. This very low output dimension allows for near realtime correspondence search with 0.1 ms per feature point on a standard PC. Our approach is sensor- and sceneagnostic because of SDV, LRF and learning highly descriptive features with fully convolutional layers. We show that 3DSmoothNet trained only on RGB-D indoor scenes of buildings achieves 79.0\% average recall on laser scans of outdoor vegetation, more than double the performance of our closest, learning-based competitors [49, 17, 5, 4]. Code, data and pre-trained models are available online at https://github.com/zgojcic/3DSmoothNet.},
	language = {en},
	urldate = {2022-01-27},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Gojcic, Zan and Zhou, Caifa and Wegner, Jan D. and Wieser, Andreas},
	month = jun,
	year = {2019},
	pages = {5540--5549},
	file = {Gojcic et al. - 2019 - The Perfect Match 3D Point Cloud Matching With Sm.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\JCML4MVQ\\Gojcic et al. - 2019 - The Perfect Match 3D Point Cloud Matching With Sm.pdf:application/pdf},
}

@article{pascacio_collaborative_2021,
	title = {Collaborative {Indoor} {Positioning} {Systems}: {A} {Systematic} {Review}},
	volume = {21},
	shorttitle = {Collaborative {Indoor} {Positioning} {Systems}},
	doi = {10.3390/s21031002},
	abstract = {Research and development in Collaborative Indoor Positioning Systems (CIPSs) is growing steadily due to their potential to improve on the performance of their non-collaborative counterparts. In contrast to the outdoors scenario, where Global Navigation Satellite System is widely adopted, in (collaborative) indoor positioning systems a large variety of technologies, techniques, and methods is being used. Moreover, the diversity of evaluation procedures and scenarios hinders a direct comparison. This paper presents a systematic review that gives a general view of the current CIPSs. A total of 84 works, published between 2006 and 2020, have been identified. These articles were analyzed and classified according to the described system’s architecture, infrastructure, technologies, techniques, methods, and evaluation. The results indicate a growing interest in collaborative positioning, and the trend tend to be towards the use of distributed architectures and infrastructure-less systems. Moreover, the most used technologies to determine the collaborative positioning between users are wireless communication technologies (Wi-Fi, Ultra-WideBand, and Bluetooth). The predominant collaborative positioning techniques are Received Signal Strength Indication, Fingerprinting, and Time of Arrival/Flight, and the collaborative methods are particle filters, Belief Propagation, Extended Kalman Filter, and Least Squares. Simulations are used as the main evaluation procedure. On the basis of the analysis and results, several promising future research avenues and gaps in research were identified.},
	journal = {Sensors},
	author = {Pascacio, Pável and Casteleyn, Sven and Torres-Sospedra, Joaquín and Lohan, Elena Simona and Nurmi, Jari},
	month = feb,
	year = {2021},
	pages = {1002},
	file = {Full Text:C\:\\Users\\max.van.schendel\\Zotero\\storage\\I9QH8KWZ\\Pascacio et al. - 2021 - Collaborative Indoor Positioning Systems A System.pdf:application/pdf},
}

@article{li_general_2010,
	title = {A {General} {Purpose} {Feature} {Extractor} for {Light} {Detection} and {Ranging} {Data}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/10/11/10356},
	doi = {10.3390/s101110356},
	abstract = {Feature extraction is a central step of processing Light Detection and Ranging (LIDAR) data. Existing detectors tend to exploit characteristics of specific environments: corners and lines from indoor (rectilinear) environments, and trees from outdoor environments. While these detectors work well in their intended environments, their performance in different environments can be poor. We describe a general purpose feature detector for both 2D and 3D LIDAR data that is applicable to virtually any environment. Our method adapts classic feature detection methods from the image processing literature, specifically the multi-scale Kanade-Tomasi corner detector. The resulting method is capable of identifying highly stable and repeatable features at a variety of spatial scales without knowledge of environment, and produces principled uncertainty estimates and corner descriptors at same time. We present results on both software simulation and standard datasets, including the 2D Victoria Park and Intel Research Center datasets, and the 3D MIT DARPA Urban Challenge dataset.},
	language = {en},
	number = {11},
	urldate = {2022-01-24},
	journal = {Sensors},
	author = {Li, Yangming and Olson, Edwin B.},
	month = nov,
	year = {2010},
	note = {Number: 11
Publisher: Molecular Diversity Preservation International},
	keywords = {SLAM, descriptors, feature detection, LIDARs, uncertainty estimates},
	pages = {10356--10375},
	file = {Full Text PDF:C\:\\Users\\max.van.schendel\\Zotero\\storage\\R529KC7E\\Li and Olson - 2010 - A General Purpose Feature Extractor for Light Dete.pdf:application/pdf;Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\HZCAACQ8\\10356.html:text/html},
}

@article{blanco_robust_2013,
	title = {A robust, multi-hypothesis approach to matching occupancy grid maps},
	volume = {31},
	issn = {0263-5747, 1469-8668},
	url = {https://www.cambridge.org/core/journals/robotica/article/abs/robust-multihypothesis-approach-to-matching-occupancy-grid-maps/D08647A0FB96405317B60BFF9F7D890A},
	doi = {10.1017/S0263574712000732},
	abstract = {This paper presents a new approach to matching occupancy grid maps by means of finding correspondences between a set of sparse features detected in the maps. The problem is stated here as a special instance of generic image registration. To cope with the uncertainty and ambiguity that arise from matching grid maps, we introduce a modified RANSAC algorithm which searches for a dynamic number of internally consistent subsets of feature pairings from which to compute hypotheses about the translation and rotation between the maps. By providing a (possibly multi-modal) probability distribution of the relative pose of the maps, our method can be seamlessly integrated into large-scale mapping frameworks for mobile robots. This paper provides a benchmarking of different detectors and descriptors, along extensive experimental results that illustrate the robustness of the algorithm with a 97\% success ratio in loop-closure detection for {\textasciitilde}1700 matchings between local maps obtained from four publicly available datasets.},
	language = {en},
	number = {5},
	urldate = {2022-01-24},
	journal = {Robotica},
	author = {Blanco, Jose-Luis and González-Jiménez, Javier and Fernández-Madrigal, Juan-Antonio},
	month = aug,
	year = {2013},
	note = {Publisher: Cambridge University Press},
	keywords = {SLAM, Mobile robots, navigation, Pose estimation and registration, Robot localization},
	pages = {687--701},
	file = {Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\WD9FCWQA\\D08647A0FB96405317B60BFF9F7D890A.html:text/html},
}

@book{russell_artificial_2010,
	address = {Upper Saddle River},
	edition = {3rd ed},
	series = {Prentice {Hall} series in artificial intelligence},
	title = {Artificial intelligence: a modern approach},
	isbn = {978-0-13-604259-4},
	shorttitle = {Artificial intelligence},
	language = {en},
	publisher = {Prentice Hall},
	author = {Russell, Stuart J. and Norvig, Peter and Davis, Ernest},
	year = {2010},
	keywords = {Artificial intelligence},
	file = {Russell et al. - 2010 - Artificial intelligence a modern approach.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\2RTUD6QZ\\Russell et al. - 2010 - Artificial intelligence a modern approach.pdf:application/pdf},
}

@article{wooldridge_intelligent_1995,
	title = {Intelligent agents: theory and practice},
	shorttitle = {Intelligent agents},
	doi = {10.1017/S0269888900008122},
	abstract = {The aim in this paper is to point the reader at what they perceive to be the most important theoretical and practical issues associated with the design and construction of intelligent agents. The concept of an agent has become important in both Artificial Intelligence (AI) and mainstream computer science. Our aim in this paper is to point the reader at what we perceive to be the most important theoretical and practical issues associated with the design and construction of intelligent agents. For convenience, we divide these issues into three areas (though as the reader will see, the divisions are at times somewhat arbitrary). Agent theory is concerned with the question of what an agent is, and the use of mathematical formalisms for representing and reasoning about the properties of agents. Agent architectures can be thought of as software engineering models of agents;researchers in this area are primarily concerned with the problem of designing software or hardware systems that will satisfy the properties specified by agent theorists. Finally, agent languages are software systems for programming and experimenting with agents; these languages may embody principles proposed by theorists. The paper is not intended to serve as a tutorial introduction to all the issues mentioned; we hope instead simply to identify the most important issues, and point to work that elaborates on them. The article includes a short review of current and potential applications of agent technology.},
	journal = {Knowl. Eng. Rev.},
	author = {Wooldridge, M. and Jennings, N.},
	year = {1995},
	file = {Wooldridge and Jennings - 1995 - Intelligent agents theory and practice.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\TWAKBYWA\\Wooldridge and Jennings - 1995 - Intelligent agents theory and practice.pdf:application/pdf},
}

@incollection{goos_implementing_1999,
	address = {Berlin, Heidelberg},
	title = {Implementing {Hierarchical} {Graph}-{Structures}},
	volume = {1577},
	isbn = {978-3-540-65718-7 978-3-540-49020-3},
	abstract = {We present concepts for the implementation of hierarchical graphs, which can be used as basis for the implementation of tools for graphical formal description techniques (gFDT) like SDL or statecharts. Our approach provides a strong modularity of a speciﬁcation by a loose coupling between diﬀerent hierarchy levels and it serves for a rapid development of interactive editors for gFDTs by a special technique of describing hierarchy. Furthermore, this technique allows the reuse of graph editors in diﬀerent applications. Our concepts are explained by means of the graphical design tool Moby/plc for a special class of real-time automata, called PLC-Automata.},
	language = {en},
	urldate = {2022-01-23},
	booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
	publisher = {Springer Berlin Heidelberg},
	author = {Tapken, Josef},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Finance, Jean-Pierre},
	year = {1999},
	pages = {219--233},
	file = {Tapken - 1999 - Implementing Hierarchical Graph-Structures.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\LMKKE2K5\\Tapken - 1999 - Implementing Hierarchical Graph-Structures.pdf:application/pdf},
}

@article{tamke_point_2014,
	title = {From {Point} {Clouds} to {Deﬁnitions} of {Architectural} {Space}},
	language = {en},
	author = {Tamke, Martin and Blümel, Ina and Ochmann, Sebastian and Vock, Richard and Wessel, Raoul},
	year = {2014},
	pages = {10},
	file = {Tamke et al. - From Point Clouds to Deﬁnitions of Architectural S.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\2CAQQA2B\\Tamke et al. - From Point Clouds to Deﬁnitions of Architectural S.pdf:application/pdf},
}

@article{blochliger_topomap_2018,
	title = {Topomap: {Topological} {Mapping} and {Navigation} {Based} on {Visual} {SLAM} {Maps}},
	shorttitle = {Topomap},
	url = {http://arxiv.org/abs/1709.05533},
	abstract = {Visual robot navigation within large-scale, semi-structured environments deals with various challenges such as computation intensive path planning algorithms or insufficient knowledge about traversable spaces. Moreover, many state-of-the-art navigation approaches only operate locally instead of gaining a more conceptual understanding of the planning objective. This limits the complexity of tasks a robot can accomplish and makes it harder to deal with uncertainties that are present in the context of real-time robotics applications. In this work, we present Topomap, a framework which simplifies the navigation task by providing a map to the robot which is tailored for path planning use. This novel approach transforms a sparse feature-based map from a visual Simultaneous Localization And Mapping (SLAM) system into a three-dimensional topological map. This is done in two steps. First, we extract occupancy information directly from the noisy sparse point cloud. Then, we create a set of convex free-space clusters, which are the vertices of the topological map. We show that this representation improves the efficiency of global planning, and we provide a complete derivation of our algorithm. Planning experiments on real world datasets demonstrate that we achieve similar performance as RRT* with significantly lower computation times and storage requirements. Finally, we test our algorithm on a mobile robotic platform to prove its advantages.},
	urldate = {2022-01-23},
	journal = {arXiv:1709.05533 [cs]},
	author = {Blöchliger, Fabian and Fehr, Marius and Dymczyk, Marcin and Schneider, Thomas and Siegwart, Roland},
	month = mar,
	year = {2018},
	note = {arXiv: 1709.05533},
	keywords = {Computer Science - Robotics},
	annote = {Comment: 8 pages},
	file = {arXiv Fulltext PDF:C\:\\Users\\max.van.schendel\\Zotero\\storage\\I6BMCHQ8\\Blöchliger et al. - 2018 - Topomap Topological Mapping and Navigation Based .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\max.van.schendel\\Zotero\\storage\\LPKLFYM9\\1709.html:text/html},
}

@article{wessel_room_2008,
	title = {The {Room} {Connectivity} {Graph}: {Shape} {Retrieval} in the {Architectural} {Domain}},
	abstract = {While advances in CAD modeling techniques led to an ever increasing number of available architectural 3D models, reusability of these models as templates or as inspiration sources is still very limited. One reason for this is that there exist basically no shape retrieval methods specialized in the architectural domain. In this work, we therefore present a method to efﬁciently characterize 3D architectural models according to the underlying arrangement of their rooms by a room connectivity graph. In this graph, rooms are represented by attributed nodes. Connections between rooms, i.e. doors or windows, are represented by attributed edges. We show that these attributed graphs can be used for an efﬁcient retrieval of 3D architectural models using fast graph matching techniques.},
	language = {en},
	author = {Wessel, Raoul and Blümel, Ina and Klein, Reinhard},
	year = {2008},
	pages = {8},
	file = {Wessel et al. - The Room Connectivity Graph Shape Retrieval in th.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\BU6Q27AD\\Wessel et al. - The Room Connectivity Graph Shape Retrieval in th.pdf:application/pdf},
}

@article{ochmann_towards_nodate,
	title = {Towards the {Extraction} of {Hierarchical} {Building} {Descriptions} from {3D} {Indoor} {Scans}},
	abstract = {We present a new method for the hierarchical decomposition of 3D indoor scans and the subsequent generation of an according hierarchical graph-based building descriptor. The hierarchy consists of four basic levels with according entities, building - storey - room - object. All entities are represented as attributed nodes in a graph and are linked to the upper level entity they are located in. Additionally, nodes of the same level are linked depending on their spatial and topological relationship. The hierarchical description enables easy navigation in the formerly unstructured data, measurement takings, as well as carrying out retrieval tasks that incorporate geometric, topological, and also functional building properties describing e.g. the designated use of single rooms according to the objects it contains. In contrast to previous methods which either focus on the segmentation into rooms or on the recognition of indoor objects, our holistic approach incorporates a rather large spectrum of entities on different semantic levels that are inherent to 3D building representations. In our evaluation we show the feasibility of our method for extraction of hierarchical building descriptions for various tasks using synthetic as well as real world data.},
	language = {en},
	author = {Ochmann, S and Vock, R and Wessel, R and Klein, R},
	pages = {8},
}

@inproceedings{kuipers_local_2004,
	address = {New Orleans, LA, USA},
	title = {Local metrical and global topological maps in the hybrid spatial semantic hierarchy},
	isbn = {978-0-7803-8232-9},
	url = {http://ieeexplore.ieee.org/document/1302485/},
	doi = {10.1109/ROBOT.2004.1302485},
	abstract = {Topological and metrical methods for representing spatial knowledge have complementary strengths. We present a hybrid extension to the Spatial Semantic Hierarchy that combines their strengths and avoids their weaknesses. Metrical SLAM methods are used to build local maps of small-scale space within the sensory horizon of the agent, while topological methods are used to represent the structure of large-scale space. We describe how a local perceptual map is analyzed to identify a local topology description and is abstracted to a topological place. The mapbuilding method creates a set of topological map hypotheses that are consistent with travel experience. The set of maps is guaranteed under reasonable assumptions to include the correct map. We demonstrate the method on a real environment with multiple nested large-scale loops.},
	language = {en},
	urldate = {2022-01-23},
	booktitle = {{IEEE} {International} {Conference} on {Robotics} and {Automation}, 2004. {Proceedings}. {ICRA} '04. 2004},
	publisher = {IEEE},
	author = {Kuipers, B. and Modayil, J. and Beeson, P. and MacMahon, M. and Savelli, F.},
	year = {2004},
	pages = {4845--4851 Vol.5},
	file = {Kuipers et al. - 2004 - Local metrical and global topological maps in the .pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\784UZWJ8\\Kuipers et al. - 2004 - Local metrical and global topological maps in the .pdf:application/pdf},
}

@phdthesis{volodine_point_2007,
	title = {Point {Cloud} {Processing} {Using} {Linear} {Algebra} and {Graph} {Theory}},
	author = {Volodine, Tim},
	year = {2007},
	file = {TW2007_05.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\MWVFGYAC\\TW2007_05.pdf:application/pdf},
}

@article{carpin_map_2005-2,
	title = {On map merging},
	volume = {53},
	issn = {09218890},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0921889005001041},
	doi = {10.1016/j.robot.2005.07.001},
	abstract = {We illustrate our experience in developing and implementing algorithms for map merging, i.e., the problem of fusing two or more partial maps without common reference frames into one large global map. The partial maps may for example be acquired by multiple robots or during several runs of a single robot from varying starting positions. Our work deals with low quality maps based on probabilistic grids, motivated by the goal to develop multiple mobile platforms to be used in rescue environments. Several important contributions to map merging are presented. First of all, we treat map merging as a motion planning problem. The merging process can be done by rotating and translating the partial maps until identical regions overlap, somewhat similar to protein docking. Second, a motion planning algorithm is presented which is particular suited for this task. Third, a special metric is presented which guides the motion planning algorithm toward the goal of optimally overlapping partial maps. Results with our approach are presented based on data gathered from real robots developed for the real robot rescue league of RoboCup.},
	language = {en},
	number = {1},
	urldate = {2022-01-21},
	journal = {Robotics and Autonomous Systems},
	author = {Carpin, Stefano and Birk, Andreas and Jucikas, Viktoras},
	month = oct,
	year = {2005},
	pages = {1--14},
	file = {Carpin et al. - 2005 - On map merging.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\LSKJXTYG\\Carpin et al. - 2005 - On map merging.pdf:application/pdf},
}

@article{kobayashi_spatial_1994,
	title = {On the spatial graph},
	volume = {17},
	issn = {0386-5991},
	url = {https://projecteuclid.org/journals/kodai-mathematical-journal/volume-17/issue-3/On-the-spatial-graph/10.2996/kmj/1138040046.full},
	doi = {10.2996/kmj/1138040046},
	language = {en},
	number = {3},
	urldate = {2022-01-21},
	journal = {Kodai Mathematical Journal},
	author = {Kobayashi, Kazuaki},
	month = jan,
	year = {1994},
	file = {Kobayashi - 1994 - On the spatial graph.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\U63YVZZT\\Kobayashi - 1994 - On the spatial graph.pdf:application/pdf},
}

@inproceedings{hermann_design_2016,
	title = {Design {Principles} for {Industrie} 4.0 {Scenarios}},
	doi = {10.1109/HICSS.2016.488},
	abstract = {The increasing integration of the Internet of Everything into the industrial value chain has built the foundation for the next industrial revolution called Industrie 4.0. Although Industrie 4.0 is currently a top priority for many companies, research centers, and universities, a generally accepted understanding of the term does not exist. As a result, discussing the topic on an academic level is difficult, and so is implementing Industrie 4.0 scenarios. Based on a quantitative text analysis and a qualitative literature review, the paper identifies design principles of Industrie 4.0. Taking into account these principles, academics may be enabled to further investigate on the topic, while practitioners may find assistance in identifying appropriate scenarios. A case study illustrates how the identified design principles support practitioners in identifying Industrie 4.0 scenarios.},
	booktitle = {2016 49th {Hawaii} {International} {Conference} on {System} {Sciences} ({HICSS})},
	author = {Hermann, Mario and Pentek, Tobias and Otto, Boris},
	month = jan,
	year = {2016},
	note = {ISSN: 1530-1605},
	keywords = {Case Study, Companies, Design Principles, Industrie 4.0, Industries, Industry 4.0, Internet, Internet of Everything, Internet of Things, Production facilities, Smart Factory, Text analysis},
	pages = {3928--3937},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\max.van.schendel\\Zotero\\storage\\GQ8FCGZI\\7427673.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\max.van.schendel\\Zotero\\storage\\9P3FI3YN\\Hermann et al. - 2016 - Design Principles for Industrie 4.0 Scenarios.pdf:application/pdf},
}

@article{tomaszewski_geographic_2015,
	title = {Geographic {Information} {Systems} ({GIS}) for {Disaster} {Management}},
	language = {en},
	author = {Tomaszewski, Brian},
	year = {2015},
	pages = {304},
	file = {Tomaszewski - Geographic Information Systems (GIS) for Disaster .pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\DAUJCPXR\\Tomaszewski - Geographic Information Systems (GIS) for Disaster .pdf:application/pdf},
}

@book{national_academies_successful_2007,
	address = {Washington, D.C.},
	title = {Successful {Response} {Starts} with a {Map}: {Improving} {Geospatial} {Support} for {Disaster} {Management}},
	isbn = {978-0-309-10340-4},
	shorttitle = {Successful {Response} {Starts} with a {Map}},
	url = {http://www.nap.edu/catalog/11793},
	language = {en},
	urldate = {2022-08-15},
	publisher = {National Academies Press},
	author = {{National Academies}},
	month = dec,
	year = {2007},
	doi = {10.17226/11793},
	note = {Pages: 11793},
	file = {2007 - Successful Response Starts with a Map Improving G.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\DEPNITEN\\2007 - Successful Response Starts with a Map Improving G.pdf:application/pdf},
}

@article{mathiassen_demonstrating_2021,
	title = {Demonstrating interoperability between unmanned ground systems and command and control systems},
	abstract = {This paper describes the research and experiment efforts of the NATO STO group IST-149-RTG capability concept demonstrator for interoperability within unmanned ground systems and C2 and the NAAG team of experts on UGV. The main purpose of the group was to investigate possible standards for controlling UGVs and tests them in a real world scenario. The efforts have been two folded, where the first effort was two NATO groups having an experiment demonstrating interoperability between the UGVs and OCUs available within the group. The Belgium contribution is done in the EU project ICARUS. Both efforts used the Joint Architecture for Unmanned Systems (JAUS) with the interoperability profile (IOP) to successfully enable interoperability between the systems. The trials showed that it is possible to extend the systems quite easily and achieve compliance with parts of the standard in a relatively short time.},
	language = {en},
	author = {Mathiassen, Kim and Schneider, Frank E and Bounker, Paul and Tiderko, Alexander},
	year = {2021},
	pages = {30},
	file = {Mathiassen et al. - Demonstrating interoperability between unmanned gr.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\GQC26EHP\\Mathiassen et al. - Demonstrating interoperability between unmanned gr.pdf:application/pdf},
}

@misc{kubelka_gravity-constrained_2022,
	title = {Gravity-constrained point cloud registration},
	url = {http://arxiv.org/abs/2203.13799},
	abstract = {Visual and lidar Simultaneous Localization and Mapping (SLAM) algorithms beneﬁt from the Inertial Measurement Unit (IMU) modality. The high-rate inertial data complement the other lower-rate modalities. Moreover, in the absence of constant acceleration, the gravity vector makes two attitude angles out of three observable in the global coordinate frame. In visual odometry, this is already being used to reduce the 6-Degrees Of Freedom (DOF) pose estimation problem to 4DOF. In lidar SLAM, the gravity measurements are often used as a penalty in the back-end global map optimization to prevent map deformations. In this work, we propose an Iterative Closest Point (ICP)-based front-end which exploits the observable DOF and provides pose estimates aligned with the gravity vector. We believe that this front-end has the potential to support the loop closure identiﬁcation, thus speeding up convergences of global map optimizations. The presented approach has been extensively tested in large-scale outdoor environments as well as in the Subterranean Challenge organized by Defense Advanced Research Projects Agency (DARPA). We show that it can reduce the localization drift by 30 \% when compared to the standard 6-DOF ICP. Moreover, the code is readily available to the community as a part of the libpointmatcher library.},
	language = {en},
	urldate = {2022-08-29},
	publisher = {arXiv},
	author = {Kubelka, Vladimír and Vaidis, Maxime and Pomerleau, François},
	month = mar,
	year = {2022},
	note = {arXiv:2203.13799 [cs]},
	keywords = {Computer Science - Robotics},
	annote = {Comment: Preprint. Submitted to IROS 2022. 7 pages, 9 figures},
	file = {Kubelka et al. - 2022 - Gravity-constrained point cloud registration.pdf:C\:\\Users\\max.van.schendel\\Zotero\\storage\\2JUJVSBA\\Kubelka et al. - 2022 - Gravity-constrained point cloud registration.pdf:application/pdf},
}
